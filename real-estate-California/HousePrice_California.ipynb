{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thông tin nhóm 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1612406 - Đặng Phương Nam\n",
    "\n",
    "1612423 - Lê Minh nghĩa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Câu hỏi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cho các thông tin về căn nhà:\n",
    "\n",
    "- Giá cho thuê trước khi bán.\n",
    "- Địa chỉ.\n",
    "- Loại nhà.\n",
    "- Số phòng ngủ.\n",
    "- Số nhà vệ sinh.\n",
    "- Diện tích phần nhà.\n",
    "- Diện tích toàn bộ lô đất.\n",
    "- Năm xây dựng.\n",
    "- Tiền thuế.\n",
    "- Gần mấy trường học.\n",
    "- Tình hình tội phạm.\n",
    "- ...\n",
    "\n",
    "Hỏi giá trị của căn nhà là bao nhiêu tiền?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lợi ích khi trả lời được câu hỏi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhờ vào thông tin của căn nhà:\n",
    "\n",
    "- Người bán có thể dự đoán được giá trị căn nhà mà mình muốn bán.\n",
    "- Người mua có thể ước lượng được căn nhà mình muốn mua có giá cả hợp lý hay không?.\n",
    "- Dự đoán được giá trị căn nhà của mình.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 3. Thu thập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Parse HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu thu thập từ trang web https://www.realtytrac.com/. Ta chỉ thu thập dữ liệu \"các estate đã được bán tại  California\", ta có HTML cần parse: https://m.realtytrac.com/mapsearch/sold/ca/\n",
    "\n",
    "Thời gian lấy dữ liệu: Ngày 10/12/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết.\n",
    "import urllib.robotparser\n",
    "import json\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('https://m.realtytrac.com/robots.txt')\n",
    "rp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy link chứa danh sách các ngôi nhà đã bán theo Quận tại California\n",
    "check_parse = rp.can_fetch('*', 'https://m.realtytrac.com/mapsearch/sold/ca/')\n",
    "\n",
    "base_url = \"https://m.realtytrac.com\"\n",
    "list_url_county = []\n",
    "\n",
    "# Kiểm tra việc parse HTML được cho phép hay không?\n",
    "if check_parse == True:\n",
    "    session = HTMLSession()\n",
    "    r = session.get('https://m.realtytrac.com/mapsearch/sold/ca/')\n",
    "\n",
    "    counties = r.html.find(\"option\")\n",
    "\n",
    "    for county in counties:\n",
    "        tail_url = county.attrs['value']\n",
    "        if (tail_url):\n",
    "            url = base_url + tail_url\n",
    "            list_url_county.append(url)\n",
    "\n",
    "\n",
    "list_url_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm trả về generator, generator này trả về trang tiếp theo sau mỗi lần duyệt.\n",
    "def urlGenerator(baseUrl, startPage=1):\n",
    "    i = startPage\n",
    "    if i <= 1:\n",
    "        yield baseUrl\n",
    "        i = 2\n",
    "    while True:\n",
    "        yield f\"{baseUrl}/p-{i}\"\n",
    "        i += 1\n",
    "\n",
    "\n",
    "# Hàm parseDetailPage: parse để lấy thông tin chi tiết của từng căn nhà từ detailUrl (của căn nhà đã bán).\n",
    "# Tham số: session và detailUrl của căn nhà cần parse.\n",
    "# Trả về: dictionary chứa các thông tin đã parse được.\n",
    "def parseDetailPage(session: HTMLSession, detailUrl: str):\n",
    "\n",
    "    # Lấy mã HTML của trang web.\n",
    "    r = session.get(detailUrl)\n",
    "\n",
    "    # Dictionary lưu lại kết quả.\n",
    "    result = {}\n",
    "\n",
    "    # Lấy address của estate.\n",
    "    address = {}\n",
    "    street = r.html.find(\"[itemprop = 'streetAddress']\", first=True)\n",
    "    if street is not None:\n",
    "        street = street.text\n",
    "\n",
    "    locality = r.html.find(\"[itemprop = 'addressLocality']\", first=True)\n",
    "    if locality is not None:\n",
    "        locality = locality.text\n",
    "\n",
    "    region = r.html.find(\"[itemprop = 'addressRegion']\", first=True)\n",
    "    if region is not None:\n",
    "        region = region.text\n",
    "\n",
    "    code = r.html.find(\"[itemprop = 'postalCode']\", first=True)\n",
    "    if code is not None:\n",
    "        code = code.text\n",
    "\n",
    "    address[\"street\"] = street\n",
    "    address[\"locality\"] = locality\n",
    "    address[\"region\"] = region\n",
    "    address[\"code\"] = code\n",
    "\n",
    "    result[\"address\"] = address\n",
    "\n",
    "    # Lấy thông tin ngày đã bán căn nhà.\n",
    "    date_sold = r.html.find(\".recently-sold\", first=True)\n",
    "    if date_sold is not None:\n",
    "        result[\"date_sold\"] = date_sold.text.replace(\"SOLD ON \", \"\")\n",
    "    else:\n",
    "        result[\"date_sold\"] = None\n",
    "\n",
    "    # Lấy giá cho thuê trước khi bán.\n",
    "    mortgage = r.html.find(\".property-price-info\", first=True)\n",
    "    if mortgage is not None:\n",
    "        result[\"mortgage\"] = mortgage.text.replace(\"Est. Mortgage: \",\"\")\n",
    "    else:\n",
    "        result[\"mortgage\"] = None\n",
    "\n",
    "\n",
    "    # Lấy phân mô tả chi tiết về căn nhà.\n",
    "    details = []\n",
    "    detailTexts = r.html.find(\".detail-text\")\n",
    "    if detailTexts is not None:\n",
    "        for detailText in detailTexts:\n",
    "            details.append(detailText.html)  # sở dĩ lấy mà HTML để dễ parse sau này (khi muốn lấy thông tin từ details)\n",
    "    result[\"details\"] = details\n",
    "\n",
    "    # Lấy property info của căn nhà.\n",
    "    propertyInfo = r.html.find(\".property-info\", first=True)\n",
    "    if propertyInfo is not None:\n",
    "        info = {}\n",
    "        items = propertyInfo.find(\".item\")\n",
    "        if items is not None:\n",
    "            for item in items:\n",
    "                name = item.find(\".name\", first=True).text.lower().replace(\" \", \"_\")\n",
    "                value = item.find(\".value\", first=True).text\n",
    "                info[name] = value\n",
    "\n",
    "        result[\"info\"] = info\n",
    "    else:\n",
    "        result[\"info\"] = None\n",
    "\n",
    "    # Lấy property taxes của căn nhà.\n",
    "    property_taxes = r.html.find(\".property-taxes\")\n",
    "    if property_taxes is not None:\n",
    "        for tax in property_taxes:\n",
    "            key = tax.find(\".section-head\", first=True).text.lower().replace(\" \", \"_\")\n",
    "            taxes = {}\n",
    "            items = tax.find(\".item\")\n",
    "            if items is not None:\n",
    "                for item in items:\n",
    "                    name = item.find(\".name\", first=True).text.lower().replace(\" \", \"_\")\n",
    "                    value = item.find(\".value\", first=True).text\n",
    "                    taxes[name] = value\n",
    "\n",
    "            result[key] = taxes\n",
    "\n",
    "    # Lấy số lượng trường học gần đó.\n",
    "    local_school = r.html.find(\".property-schools\", first=True)\n",
    "    num_school = 0\n",
    "    if local_school is not None:\n",
    "        num_school = len(local_school.find(\".schoolInfo\"))\n",
    "\n",
    "    result[\"school\"] = num_school\n",
    "\n",
    "    # Lấy thông tin tội phạm trong vùng.\n",
    "    crimes = {}\n",
    "    local_crime_index = r.html.find(\".property-local-crime\", first=True)\n",
    "    if local_crime_index is not None:\n",
    "        type_crimes = local_crime_index.find(\".gradeTitle\")\n",
    "        if type_crimes is not None:\n",
    "            for type_crime in type_crimes:\n",
    "                match = re.match(r\"(.+?) = (\\d+)\", type_crime.text)\n",
    "                if match is not None:\n",
    "                    key = match.group(1).lower().replace(' ', '_')\n",
    "                    value = int(match.group(2))\n",
    "                    crimes[key] = value\n",
    "\n",
    "    result[\"local_crime_index\"] = crimes\n",
    "\n",
    "    # Lấy số lượng nhà bị tịch thu gần đó.\n",
    "    nearby_foreclosures = r.html.find(\".property-nearby-fc\", first=True)\n",
    "    num_fc = 0\n",
    "    if nearby_foreclosures is not None:\n",
    "        num_fc = len(nearby_foreclosures.find(\".nearby-property\"))\n",
    "\n",
    "    result[\"foreclosures\"] = num_fc\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm parseSearchPage: parse theo page (mỗi parse chứa danh sách và url của 25 căn nhà đã được bán).\n",
    "# Tham số: session và url của page hiện tại.\n",
    "# Trả về: list thông tin chi tiết của tất cả căn nhà tại page hiện tại và url của page kế tiếp.\n",
    "def parseSearchPage(session: HTMLSession, urlPage: str):\n",
    "\n",
    "    # Lấy mã HTML.\n",
    "    r = session.get(urlPage)\n",
    "\n",
    "    # Lấu detailUrl của tất cả bất động sản.\n",
    "    detailUrls = [link for link in r.html.absolute_links if 'property' in link]\n",
    "\n",
    "    results = []  # List chứa kết quả parse được tại page.\n",
    "\n",
    "    # Tiến hành parse từ detailUrl\n",
    "    for detailUrl in detailUrls:\n",
    "        # Kiểm tra việc parse HTML được cho phép hay không?\n",
    "        if not rp.can_fetch('*', detailUrl):\n",
    "            print(f\"SKIP: {detailUrl}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Parsing detail url {detailUrl}\")\n",
    "        result = parseDetailPage(session, detailUrl)\n",
    "        results.append(result)\n",
    "\n",
    "    nextPageAnchor = r.html.find(\".current + .page\", first=True)\n",
    "    return results, nextPageAnchor is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm getAllCountyProperties: parse tất cả các page của một County để lấy thông tin chi tiết của \n",
    "# căn nhà được bán thành công.\n",
    "# Tham số: session và countryUrl chứa thông tin các căn nhà được bán của một County.\n",
    "# Trả về: File chứa kết quả đã parse thành công (tên file là tên County được parse).\n",
    "def getAllCountyProperties(session: HTMLSession, countyUrl: str):\n",
    "    # Lấy tên County từ urlCounty.\n",
    "    if countyUrl.endswith(\"/\"):\n",
    "        countyUrl = countyUrl[:-1]\n",
    "    fileName = f\"data/{os.path.basename(countyUrl)}.json\"\n",
    "\n",
    "    # Kiểm tra sự tồn tại file.\n",
    "    if os.path.exists(fileName):\n",
    "        print(f\"FILE EXISTS: {fileName}\")\n",
    "        return\n",
    "\n",
    "    # Mở file để ghi dữ liệu (kiểu file là json)\n",
    "    with open(fileName, \"a\") as fOut:\n",
    "        for url in urlGenerator(countyUrl, 1):\n",
    "            # Kiểm tra việc parse HTML được cho phép hay không?\n",
    "            if not rp.can_fetch('*', url):\n",
    "                print(f\"SKIP: {url}\")\n",
    "                continue\n",
    "\n",
    "            # Tiến hành parse theo từng page.\n",
    "            print(f\"Parsing {url}\")\n",
    "            results, nextPage = parseSearchPage(session, url)\n",
    "\n",
    "            # Ghi kết quả xuống file.\n",
    "            for result in results:\n",
    "                json.dump(result, fOut, ensure_ascii=False)\n",
    "                fOut.write(\"\\n\")\n",
    "\n",
    "            # Kiểm tra có còn page tiếp theo hay không?\n",
    "            if not nextPage:\n",
    "                break\n",
    "\n",
    "            # Mỗi lần parse 1 page thì cho sleep 2s.\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiến hành lấy dữ liệu. Lưu ý trong quá trình lấy có thể bị timeout do đường truyền mạng, nếu bị thì chỉ cần làm theo các bước sau:\n",
    "- Xem đã lấy tới page mấy. vd: \"...page-125\"\n",
    "- Đổi lại tên file trong thư mục data là \"orange-county-1.json\" chẳng hạn (số 1, 2, 3,.. là theo mỗi lần lấy dữ liệu của mình).\n",
    "- Vào hàm \"getAllCountyProperties\" đổi lại dòng \"for url in urlGenerator(countyUrl, 1)\" thành \"for url in urlGenerator(countyUrl, 125)\", số 125 là tùy mình lấy tới page thứ mấy mà bị timeout.\n",
    "- Dữ liệu tất nhiên sẽ bi trùng, cứ việc yên tâm vì phần sau sẽ xóa trung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://m.realtytrac.com/mapsearch/sold/ca/orange-county\"\n",
    "session = HTMLSession()\n",
    "getAllCountyProperties(session, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần gộp từng phần dữ liệu đã lấy dang dở lại thành 1 file.\n",
    "# Nếu không bị timeout như trường hợp ở trên thì không dùng shell code này.\n",
    "inputFiles = [\"data/orange-county-1.json\", \"data/orange-county-2.json\", \n",
    "              \"data/orange-county-3.json\", \"data/orange-county-4.json\"]\n",
    "outputFile = \"data/full-orange-county.json\"\n",
    "\n",
    "with open(outputFile, \"a+\") as fOut:\n",
    "    for inputFile in inputFiles:\n",
    "        with open(inputFile, \"r\") as fIn:\n",
    "            data = fIn.read()\n",
    "            fOut.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần convert file json sang file csv.\n",
    "\n",
    "def xstr(s):\n",
    "    return '' if s is None else str(s)\n",
    "\n",
    "\n",
    "# Hàm preprocessFile: chuyển file json sang file csv.\n",
    "# Tham số: tên file json và tên file csv.\n",
    "# Không trả về.\n",
    "def preprocessFile(inputFile: str, outputFile: str):\n",
    "\n",
    "    # Kiểm tra tồn tại file Input.\n",
    "    if os.path.exists(outputFile):\n",
    "        print(f\"FILE EXISTS: {outputFile}\")\n",
    "        return\n",
    "\n",
    "    # Kiểm tra tồn tại file Output.\n",
    "    if not os.path.exists(inputFile):\n",
    "        print(f\"Input file not found: {inputFile}\")\n",
    "        return\n",
    "\n",
    "    with open(inputFile) as fIn, open(outputFile, \"w\") as fOut:\n",
    "        tab = \"\\t\"\n",
    "        headers = (\n",
    "            \"address_street\",\n",
    "            \"address_locality\",\n",
    "            \"address_region\",\n",
    "            \"address_code\",\n",
    "            \"date_sold\",\n",
    "            \"mortgage\",\n",
    "            \"info_type\",\n",
    "            \"info_bedrooms\",\n",
    "            \"info_bathrooms\",\n",
    "            \"info_size\",\n",
    "            \"info_lot_size\",\n",
    "            \"info_year_built\",\n",
    "            \"info_est_value\",\n",
    "            \"info_sold_price\",\n",
    "            \"info_property_id\",\n",
    "            \"info_county\",\n",
    "            \"info_parcel_number\",\n",
    "            \"taxes_land\",\n",
    "            \"taxes_improvements\",\n",
    "            \"taxes_total\",\n",
    "            \"taxes_taxes\",\n",
    "            \"school\",\n",
    "            \"total_crime\",\n",
    "            \"violent_crime\",\n",
    "            \"property_crime\",\n",
    "            \"foreclosures\",\n",
    "        )\n",
    "\n",
    "        # Ghi các tên cột vào file output, mỗi cột ngăn cách bởi \"\\t\".\n",
    "        fOut.write(f\"{tab.join(headers)}\\n\")\n",
    "\n",
    "        # Duyệt từng line trong file Input (json).\n",
    "        for line in fIn:\n",
    "            row = json.loads(line)\n",
    "\n",
    "            # Lấy địa chỉ\n",
    "            address = row.get(\"address\")\n",
    "            address_street = address.get(\"street\")\n",
    "            address_locality = address.get(\"locality\")\n",
    "            address_region = address.get(\"region\")\n",
    "            address_code = address.get(\"code\")\n",
    "\n",
    "            # Lấy ngày bán thành công.\n",
    "            date_sold = row.get(\"date_sold\")\n",
    "\n",
    "            # Lấy giá cho thuê mỗi tháng (trước khi được bán).\n",
    "            mortgage = row.get(\"mortgage\")\n",
    "            if mortgage is not None:\n",
    "                mortgage = float(mortgage.replace(\"$\",\"\").replace(\",\",\"\").replace(\"/mo\",\"\").replace(\"Est. Refinance: \", \"\"))\n",
    "\n",
    "            # Lấy phần info\n",
    "            info = row.get(\"info\")\n",
    "\n",
    "            # Type.\n",
    "            info_type = info.get(\"type\")\n",
    "\n",
    "            # Bedrooms.\n",
    "            info_bedrooms = info.get(\"bedrooms\")\n",
    "            if info_bedrooms == \"Contact Agent\":\n",
    "                info_bedrooms = None\n",
    "            else:\n",
    "                info_bedrooms = float(info_bedrooms)\n",
    "\n",
    "            # Bathrooms.\n",
    "            info_bathrooms = info.get(\"bathrooms\")\n",
    "            if info_bathrooms == \"Contact Agent\":\n",
    "                info_bathrooms = None\n",
    "            else:\n",
    "                info_bathrooms = float(info_bathrooms)\n",
    "\n",
    "            # Size.\n",
    "            info_size = info.get(\"size\")\n",
    "            if info_size == \"Contact Agent\":\n",
    "                info_size = None\n",
    "            else:\n",
    "                info_size = float(info_size.replace(\",\", \"\").replace(\" sqft\", \"\"))\n",
    "\n",
    "            # Lot size.\n",
    "            info_lot_size = info.get(\"lot_size\")\n",
    "            if info_lot_size == \"Contact Agent\":\n",
    "                info_lot_size = None\n",
    "            else:\n",
    "                info_lot_size = float(info_lot_size.replace(\",\", \"\").replace(\" sqft\", \"\").replace(\" acres\", \"\"))\n",
    "\n",
    "            # Year build.\n",
    "            info_year_built = info.get(\"year_built\")\n",
    "            if info_year_built  == \"Contact Agent\":\n",
    "                info_year_built = None\n",
    "            else:\n",
    "                info_year_built = int(info_year_built)\n",
    "\n",
    "            # Est value.\n",
    "            info_est_value = info.get(\"est._value\")\n",
    "            if info_est_value is not None:\n",
    "                info_est_value = float(info_est_value.replace(\"$\", \"\").replace(\",\",\"\"))\n",
    "\n",
    "            # Sold price.\n",
    "            info_sold_price = info.get(\"sold_price\")\n",
    "            if info_sold_price is not None:\n",
    "                if info_sold_price != \"N/A\":\n",
    "                    info_sold_price = float(info_sold_price.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "\n",
    "            # ID.\n",
    "            info_property_id = info.get(\"property_id\")\n",
    "\n",
    "            # County.\n",
    "            info_county = info.get(\"county\")\n",
    "\n",
    "            # Parcel_number.\n",
    "            info_parcel_number = info.get(\"parcel_number\")\n",
    "\n",
    "            # Lấy phần Taxes.\n",
    "            taxes = row.get(\"property_taxes\")\n",
    "            taxes_land = None\n",
    "            taxes_improvements = None\n",
    "            taxes_total = None\n",
    "            taxes_taxes = None\n",
    "            if taxes is not None:\n",
    "                taxes_land = float(taxes.get(\"land\").replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "                taxes_improvements = float(taxes.get(\"improvements\").replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "                taxes_total = float(taxes.get(\"total\").replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "                taxes_taxes = taxes.get(\"taxes\").replace(\"$\", \"\").replace(\",\", \"\")\n",
    "\n",
    "            # Lấy số lượng scholl gần đó.\n",
    "            school = int(row.get(\"school\"))\n",
    "\n",
    "            # Lấy tình hình tội phạm.\n",
    "            crime = row.get(\"local_crime_index\")\n",
    "            if crime is not None:\n",
    "                total_crime = crime.get(\"total_crime\")\n",
    "                if total_crime is not None:\n",
    "                    total_crime = int(total_crime)\n",
    "                violent_crime = crime.get(\"violent_crime\")\n",
    "                if violent_crime is not None:\n",
    "                    violent_crime = int(violent_crime)\n",
    "                property_crime = crime.get(\"property_crime\")\n",
    "                if property_crime is not None:\n",
    "                    property_crime = int(property_crime)\n",
    "\n",
    "            # Lấy số lượng foreclosures gần đó.\n",
    "            foreclosures = int(row.get(\"foreclosures\"))\n",
    "\n",
    "            # Row này là tổng hợp các thông tin lấy được ở trên.\n",
    "            row = (\n",
    "                xstr(address_street),\n",
    "                xstr(address_locality),\n",
    "                xstr(address_region),\n",
    "                xstr(address_code),\n",
    "                xstr(date_sold),\n",
    "                xstr(mortgage),\n",
    "                xstr(info_type),\n",
    "                xstr(info_bedrooms),\n",
    "                xstr(info_bathrooms),\n",
    "                xstr(info_size),\n",
    "                xstr(info_lot_size),\n",
    "                xstr(info_year_built),\n",
    "                xstr(info_est_value),\n",
    "                xstr(info_sold_price),\n",
    "                xstr(info_property_id),\n",
    "                xstr(info_county),\n",
    "                xstr(info_parcel_number),\n",
    "                xstr(taxes_land),\n",
    "                xstr(taxes_improvements),\n",
    "                xstr(taxes_total),\n",
    "                xstr(taxes_taxes),\n",
    "                xstr(school),\n",
    "                xstr(total_crime),\n",
    "                xstr(violent_crime),\n",
    "                xstr(property_crime),\n",
    "                xstr(foreclosures),\n",
    "            )\n",
    "\n",
    "            # Ghi xuống file output\n",
    "            fOut.write(f\"{tab.join(row)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Sở dĩ nhóm không thêm phần `description` vào dữ liệu là bởi vì khi quan sát phần mã `html` của `description` thì phát hiện ra nó được viết theo một `format` nhất định, các thông tin số liệu của nó được lấy từ các bảng số liệu trong cùng một trang web (tức là các phần thông tin nhà, thuế,.. mà mình đã parse ở trên). Nếu số liệu nào có thì sẽ được lấy ra và tạo một câu mô tả theo `format` cho trước, còn số liệu nào không có thì hiển nhiên không xuất hiện câu đó. Như vậy, có thể kết luận là phần `description` lúc này sẽ không giúp ích gì cho chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"data/full-orange-county.json\"\n",
    "outputFile = \"data/orange-county.csv\"\n",
    "preprocessFile(inputFile, outputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Lựa chọn dữ liệu của năm 2019 và có \"correct ouput\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Xóa dữ liệu trùng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dữ liệu ban đầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu lên\n",
    "file_csv = \"data/Orange-County/orange-county.csv\"\n",
    "data_df =  pd.read_csv(file_csv, sep='\\t')\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu ban đầu có 21268 dòng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dữ liệu sau khi xóa trùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa các phần dữ liệu bị trùng\n",
    "unique_data_df = data_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem phần dữ liệu khi đã xóa trùng\n",
    "unique_data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu sau khi xóa trùng còn lại 18893 dòng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi dữ liệu xuống file csv\n",
    "unique_data_df.to_csv(\"data/Orange-County/delete-duplicate-orange.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Lấy dữ liệu của năm 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu lên\n",
    "df = pd.read_csv(\"data/Orange-County/delete-duplicate-orange.csv\", sep='\\t')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm cột năm bán vào dữ liệu\n",
    "df = df.assign(year_sold=df.date_sold.str[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem dữ liệu này thu thập của các năm nào\n",
    "df.year_sold.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chỉ lấy phần dữ liệu của năm 2019\n",
    "df = df[df.year_sold == \"2019\"]\n",
    "df.year_sold = df.year_sold.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi dữ liệu xuống file csv\n",
    "df.to_csv(\"data/Orange-County/delete-duplicate-orange-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Lấy dữ liệu của năm 2019 có \"correct output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "data_df = pd.read_csv(\"data/Orange-County/delete-duplicate-orange-2019.csv\", sep='\\t')\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu có 16011 căn nhà được bán trong 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta chỉ lấy dữ liệu có `info_sold_price` khác `null`. Như đã nói ở phần cuối của `1.1. Parse HTML` thì không thể tìm kiếm các giá trị chính xác từ phần `decription` để có thể lắp đầy giá trị `null`, mà nếu có tìm cũng chỉ toàn ra giá trị trung bình của các căn nhà được bán lân cận chứ không phải giá trị chính xác của nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_df[pd.notna(data_df[\"info_sold_price\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu còn lại là 15755.\n",
    "\n",
    "&#9889; Sau khi xóa các dòng có sold_price là `null`. Xem lại cột `info_est_value` thấy toàn `null`, cột này ý nghĩa là giá trị định giá của căn nhà trên các bản rao bán (chưa chốt giá). Nên xóa đi cột này là hoàn toàn hợp lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"info_est_value\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cần kiểm tra xem ứng với `15755` dòng dữ liệu thì phải có đúng `15755` `info_property_id` hay không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.info_property_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ổn vì có đúng `15755` `info_property_id` như mong muốn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, ta kiểm tra liệu ứng với mỗi `address_street` liệu chỉ có duy nhất một căn nhà được bán thành công hay không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_street_count = df.address_street.value_counts()\n",
    "address_street_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy có `38` `address_street` có số lượng nhà bán thành công trong năm 2019 lơn hơn 1, trong đó lại có `1600 S Disneyland Dr` có số lần xuất hiện lên đến con sô `16`, điều này hơi kỳ lạ. Vì vậy, ta cần quan sát thêm về các `addresss_street` kiểu này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy tên các addresss_street có số lượng nhà được bán trong năm 2019 nhiều hơn 1\n",
    "duplicate_addresss_street = address_street_count[address_street_count > 1].index\n",
    "duplicate_addresss_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicate_addresss_street)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thử tất cả các dòng có `address_street` là `1600 S Disneyland Dr` (hay `duplicate_addresss_street[0]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[df.address_street == duplicate_addresss_street[0]]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.info_sold_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với những dòng có cùng `address_street` mà lại khác `date_sold` và `info_sold_price` thì nên bỏ là hợp lý và khó có thể lấy được chính xác giá trị `sold_price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp tục, xem thử tất cả các dòng có `address_street` là `200 W Midway Dr ` (hay `duplicate_addresss_street[1]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[df.address_street == duplicate_addresss_street[1]]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.info_sold_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mặc dù có cùng `address_street`, cùng `date_sold` và cùng `info_sold_price` nhưng lại có các giá trị `taxes` thay đổi một cách kỳ lại + với các thông tin chính (`info_bedrooms`, `info_bathroooms`,...) bị thiếu. Phần các thông tin chính này có thể giải quyết bằng `fill miss value` (`mean`, `median`, `most`,...) nhưng phần `taxes` thì nhóm không biết xác định như thế nào cho hợp lý và gần chính xác nhất. Nên quyết định bỏ luôn các dòng dạng này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(address_street_count[address_street_count > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có `106` dòng dữ liệu bị như thế, so với `15755` dòng dữ liệu hiện có thì chúng chưa chiếm đến `1%` nên nhóm quyết định bỏ đi là hợp lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.address_street.isin(duplicate_addresss_street)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi dữ liệu xuống file csv.\n",
    "df.to_csv(\"data/Orange-County/data-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tách dữ liệu thành 2 tập train và test theo tỉ lệ 80% 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu lên\n",
    "data_df = pd.read_csv(\"data/Orange-County/data-2019.csv\", sep='\\t')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đổi tên\n",
    "data_df = data_df.rename(columns={\"info_sold_price\": \"sold_price\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách dữ liệu theo tỉ lệ 80% và 20%\n",
    "train, test = train_test_split(data_df, test_size=0.2, random_state=0)\n",
    "train.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Nhóm đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của thầy ra giống với của nhóm. Kết quả của câu lệnh `train.head().index` của nhóm ra 5 giá trị là: [2746, 8859, 11288, 2153, 12119]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi tập train\n",
    "train.to_csv(\"data/Orange-County/train-data-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi tập test\n",
    "test.to_csv(\"data/Orange-County/test-data-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_street</th>\n",
       "      <th>address_locality</th>\n",
       "      <th>address_region</th>\n",
       "      <th>address_code</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>info_type</th>\n",
       "      <th>info_bedrooms</th>\n",
       "      <th>info_bathrooms</th>\n",
       "      <th>info_size</th>\n",
       "      <th>...</th>\n",
       "      <th>taxes_land</th>\n",
       "      <th>taxes_improvements</th>\n",
       "      <th>taxes_total</th>\n",
       "      <th>taxes_taxes</th>\n",
       "      <th>school</th>\n",
       "      <th>total_crime</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>foreclosures</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13242 Amarillo Dr</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>CA</td>\n",
       "      <td>92683</td>\n",
       "      <td>10/24/2019</td>\n",
       "      <td>3157.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>...</td>\n",
       "      <td>508260.0</td>\n",
       "      <td>54780.0</td>\n",
       "      <td>563040.0</td>\n",
       "      <td>6969 (1.23 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>716 S Palomino Ln</td>\n",
       "      <td>Anaheim</td>\n",
       "      <td>CA</td>\n",
       "      <td>92807</td>\n",
       "      <td>08/16/2019</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>371674.0</td>\n",
       "      <td>148526.0</td>\n",
       "      <td>520200.0</td>\n",
       "      <td>5527 (1.06 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19702 Lancewood Plz</td>\n",
       "      <td>Yorba Linda</td>\n",
       "      <td>CA</td>\n",
       "      <td>92886</td>\n",
       "      <td>07/23/2019</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29459.0</td>\n",
       "      <td>43373.0</td>\n",
       "      <td>72832.0</td>\n",
       "      <td>1240 (1.70 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25885 Trabuco Rd Apt 59</td>\n",
       "      <td>Lake Forest</td>\n",
       "      <td>CA</td>\n",
       "      <td>92630</td>\n",
       "      <td>10/30/2019</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112879.0</td>\n",
       "      <td>93656.0</td>\n",
       "      <td>206535.0</td>\n",
       "      <td>2096 (1.01 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6742 Gate Hill Cir</td>\n",
       "      <td>Huntington Beach</td>\n",
       "      <td>CA</td>\n",
       "      <td>92648</td>\n",
       "      <td>07/15/2019</td>\n",
       "      <td>5860.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159764.0</td>\n",
       "      <td>148957.0</td>\n",
       "      <td>308721.0</td>\n",
       "      <td>3706 (1.20 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            address_street  address_locality address_region  address_code  \\\n",
       "0        13242 Amarillo Dr       Westminster             CA         92683   \n",
       "1        716 S Palomino Ln           Anaheim             CA         92807   \n",
       "2      19702 Lancewood Plz       Yorba Linda             CA         92886   \n",
       "3  25885 Trabuco Rd Apt 59       Lake Forest             CA         92630   \n",
       "4       6742 Gate Hill Cir  Huntington Beach             CA         92648   \n",
       "\n",
       "    date_sold  mortgage                info_type  info_bedrooms  \\\n",
       "0  10/24/2019    3157.0  Single Family Residence            3.0   \n",
       "1  08/16/2019    2748.0  Single Family Residence            3.0   \n",
       "2  07/23/2019    2966.0  Single Family Residence            4.0   \n",
       "3  10/30/2019    1726.0              Condominium            2.0   \n",
       "4  07/15/2019    5860.0  Single Family Residence            4.0   \n",
       "\n",
       "   info_bathrooms  info_size  ...  taxes_land  taxes_improvements  \\\n",
       "0             1.0     1090.0  ...    508260.0             54780.0   \n",
       "1             3.0     1582.0  ...    371674.0            148526.0   \n",
       "2             2.0     1440.0  ...     29459.0             43373.0   \n",
       "3             2.0     1190.0  ...    112879.0             93656.0   \n",
       "4             3.0     2193.0  ...    159764.0            148957.0   \n",
       "\n",
       "   taxes_total    taxes_taxes school  total_crime  violent_crime  \\\n",
       "0     563040.0  6969 (1.23 %)      3         97.0           79.0   \n",
       "1     520200.0  5527 (1.06 %)      3         88.0           71.0   \n",
       "2      72832.0  1240 (1.70 %)      3         22.0           12.0   \n",
       "3     206535.0  2096 (1.01 %)      3         29.0           23.0   \n",
       "4     308721.0  3706 (1.20 %)      3         57.0           47.0   \n",
       "\n",
       "   property_crime  foreclosures year_sold  \n",
       "0           140.0             4      2019  \n",
       "1           127.0             4      2019  \n",
       "2            44.0             4      2019  \n",
       "3            42.0             4      2019  \n",
       "4            82.0             4      2019  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/Orange-County/train-data-2019.csv\", sep='\\t')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12519 entries, 0 to 12518\n",
      "Data columns (total 26 columns):\n",
      "address_street        12485 non-null object\n",
      "address_locality      12519 non-null object\n",
      "address_region        12519 non-null object\n",
      "address_code          12519 non-null int64\n",
      "date_sold             12519 non-null object\n",
      "mortgage              12519 non-null float64\n",
      "info_type             12519 non-null object\n",
      "info_bedrooms         11363 non-null float64\n",
      "info_bathrooms        11371 non-null float64\n",
      "info_size             11946 non-null float64\n",
      "info_lot_size         8484 non-null float64\n",
      "info_year_built       11571 non-null float64\n",
      "sold_price            12519 non-null float64\n",
      "info_property_id      12519 non-null int64\n",
      "info_county           12519 non-null object\n",
      "info_parcel_number    12519 non-null int64\n",
      "taxes_land            12321 non-null float64\n",
      "taxes_improvements    12321 non-null float64\n",
      "taxes_total           12321 non-null float64\n",
      "taxes_taxes           12321 non-null object\n",
      "school                12519 non-null int64\n",
      "total_crime           12156 non-null float64\n",
      "violent_crime         12156 non-null float64\n",
      "property_crime        12156 non-null float64\n",
      "foreclosures          12519 non-null int64\n",
      "year_sold             12519 non-null int64\n",
      "dtypes: float64(13), int64(6), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tập train có `12519` dòng dữ liệu và `26` cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_street</th>\n",
       "      <th>address_locality</th>\n",
       "      <th>address_region</th>\n",
       "      <th>address_code</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>info_type</th>\n",
       "      <th>info_bedrooms</th>\n",
       "      <th>info_bathrooms</th>\n",
       "      <th>info_size</th>\n",
       "      <th>...</th>\n",
       "      <th>taxes_land</th>\n",
       "      <th>taxes_improvements</th>\n",
       "      <th>taxes_total</th>\n",
       "      <th>taxes_taxes</th>\n",
       "      <th>school</th>\n",
       "      <th>total_crime</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>foreclosures</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12485</td>\n",
       "      <td>12519</td>\n",
       "      <td>12519</td>\n",
       "      <td>12519.000000</td>\n",
       "      <td>12519</td>\n",
       "      <td>1.251900e+04</td>\n",
       "      <td>12519</td>\n",
       "      <td>11363.000000</td>\n",
       "      <td>11371.000000</td>\n",
       "      <td>11946.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232100e+04</td>\n",
       "      <td>1.232100e+04</td>\n",
       "      <td>1.232100e+04</td>\n",
       "      <td>12321</td>\n",
       "      <td>12519.000000</td>\n",
       "      <td>12156.000000</td>\n",
       "      <td>12156.000000</td>\n",
       "      <td>12156.000000</td>\n",
       "      <td>12519.000000</td>\n",
       "      <td>12519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12485</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>24621 Harbor View Dr Unit B</td>\n",
       "      <td>Irvine</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/28/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10555 (1.12 %)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>12517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92552.015816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.928697e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.124263</td>\n",
       "      <td>2.602102</td>\n",
       "      <td>2426.583208</td>\n",
       "      <td>...</td>\n",
       "      <td>5.009780e+05</td>\n",
       "      <td>2.826592e+05</td>\n",
       "      <td>7.836531e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.884016</td>\n",
       "      <td>54.516946</td>\n",
       "      <td>42.570171</td>\n",
       "      <td>82.203274</td>\n",
       "      <td>3.853822</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>564.557227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.526277e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008088</td>\n",
       "      <td>0.991297</td>\n",
       "      <td>7797.643516</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434805e+06</td>\n",
       "      <td>1.751883e+06</td>\n",
       "      <td>2.832966e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578382</td>\n",
       "      <td>29.778698</td>\n",
       "      <td>28.960716</td>\n",
       "      <td>37.985382</td>\n",
       "      <td>0.750273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90620.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.410000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92630.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.548000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1264.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.504430e+05</td>\n",
       "      <td>7.841300e+04</td>\n",
       "      <td>2.769060e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92677.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.339000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1671.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111640e+05</td>\n",
       "      <td>1.312930e+05</td>\n",
       "      <td>4.712400e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92804.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.610000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2377.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.119080e+05</td>\n",
       "      <td>2.319820e+05</td>\n",
       "      <td>7.320000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92887.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.078417e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>450854.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.929106e+07</td>\n",
       "      <td>9.338348e+07</td>\n",
       "      <td>1.447999e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     address_street address_locality address_region  \\\n",
       "count                         12485            12519          12519   \n",
       "unique                        12485               52              2   \n",
       "top     24621 Harbor View Dr Unit B           Irvine             CA   \n",
       "freq                              1             1107          12517   \n",
       "mean                            NaN              NaN            NaN   \n",
       "std                             NaN              NaN            NaN   \n",
       "min                             NaN              NaN            NaN   \n",
       "25%                             NaN              NaN            NaN   \n",
       "50%                             NaN              NaN            NaN   \n",
       "75%                             NaN              NaN            NaN   \n",
       "max                             NaN              NaN            NaN   \n",
       "\n",
       "        address_code   date_sold      mortgage                info_type  \\\n",
       "count   12519.000000       12519  1.251900e+04                    12519   \n",
       "unique           NaN         155           NaN                       14   \n",
       "top              NaN  06/28/2019           NaN  Single Family Residence   \n",
       "freq             NaN         232           NaN                     8162   \n",
       "mean    92552.015816         NaN  8.928697e+03                      NaN   \n",
       "std       564.557227         NaN  7.526277e+04                      NaN   \n",
       "min     90620.000000         NaN  2.000000e+00                      NaN   \n",
       "25%     92630.000000         NaN  2.548000e+03                      NaN   \n",
       "50%     92677.000000         NaN  3.339000e+03                      NaN   \n",
       "75%     92804.000000         NaN  4.610000e+03                      NaN   \n",
       "max     92887.000000         NaN  2.078417e+06                      NaN   \n",
       "\n",
       "        info_bedrooms  info_bathrooms      info_size  ...    taxes_land  \\\n",
       "count    11363.000000    11371.000000   11946.000000  ...  1.232100e+04   \n",
       "unique            NaN             NaN            NaN  ...           NaN   \n",
       "top               NaN             NaN            NaN  ...           NaN   \n",
       "freq              NaN             NaN            NaN  ...           NaN   \n",
       "mean         3.124263        2.602102    2426.583208  ...  5.009780e+05   \n",
       "std          1.008088        0.991297    7797.643516  ...  1.434805e+06   \n",
       "min          1.000000        1.000000     301.000000  ...  4.410000e+02   \n",
       "25%          2.000000        2.000000    1264.000000  ...  1.504430e+05   \n",
       "50%          3.000000        3.000000    1671.000000  ...  3.111640e+05   \n",
       "75%          4.000000        3.000000    2377.750000  ...  5.119080e+05   \n",
       "max          8.000000       11.000000  450854.000000  ...  6.929106e+07   \n",
       "\n",
       "        taxes_improvements   taxes_total     taxes_taxes        school  \\\n",
       "count         1.232100e+04  1.232100e+04           12321  12519.000000   \n",
       "unique                 NaN           NaN           11959           NaN   \n",
       "top                    NaN           NaN  10555 (1.12 %)           NaN   \n",
       "freq                   NaN           NaN              19           NaN   \n",
       "mean          2.826592e+05  7.836531e+05             NaN      2.884016   \n",
       "std           1.751883e+06  2.832966e+06             NaN      0.578382   \n",
       "min           0.000000e+00  0.000000e+00             NaN      0.000000   \n",
       "25%           7.841300e+04  2.769060e+05             NaN      3.000000   \n",
       "50%           1.312930e+05  4.712400e+05             NaN      3.000000   \n",
       "75%           2.319820e+05  7.320000e+05             NaN      3.000000   \n",
       "max           9.338348e+07  1.447999e+08             NaN      3.000000   \n",
       "\n",
       "         total_crime  violent_crime  property_crime  foreclosures year_sold  \n",
       "count   12156.000000   12156.000000    12156.000000  12519.000000   12519.0  \n",
       "unique           NaN            NaN             NaN           NaN       NaN  \n",
       "top              NaN            NaN             NaN           NaN       NaN  \n",
       "freq             NaN            NaN             NaN           NaN       NaN  \n",
       "mean       54.516946      42.570171       82.203274      3.853822    2019.0  \n",
       "std        29.778698      28.960716       37.985382      0.750273       0.0  \n",
       "min        13.000000       1.000000       23.000000      0.000000    2019.0  \n",
       "25%        29.000000      22.000000       48.000000      4.000000    2019.0  \n",
       "50%        55.000000      39.000000       82.000000      4.000000    2019.0  \n",
       "75%        71.000000      54.000000      122.000000      4.000000    2019.0  \n",
       "max       128.000000     128.000000      162.000000      4.000000    2019.0  \n",
       "\n",
       "[11 rows x 26 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Tách tập dữ liệu thành 2 phần train (70%) và validation (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách X và y\n",
    "y_sr = data_df[\"sold_price\"] # sr là viết tắt của series\n",
    "X_df = data_df.drop(\"sold_price\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([10747, 12214, 5916, 489, 12257], dtype='int64')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tách tập train và tập validation theo tỉ lệ 70%:30%\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(X_df, y_sr, test_size=0.3, random_state=0)\n",
    "train_X_df.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Nhóm đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của thầy ra giống với của nhóm. Kết quả của câu lệnh `train_X_df.head().index` của nhóm ra 5 giá trị là: [10747, 12214, 5916, 489, 12257]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8763 entries, 10747 to 2732\n",
      "Data columns (total 25 columns):\n",
      "address_street        8736 non-null object\n",
      "address_locality      8763 non-null object\n",
      "address_region        8763 non-null object\n",
      "address_code          8763 non-null int64\n",
      "date_sold             8763 non-null object\n",
      "mortgage              8763 non-null float64\n",
      "info_type             8763 non-null object\n",
      "info_bedrooms         7951 non-null float64\n",
      "info_bathrooms        7956 non-null float64\n",
      "info_size             8361 non-null float64\n",
      "info_lot_size         5931 non-null float64\n",
      "info_year_built       8099 non-null float64\n",
      "info_property_id      8763 non-null int64\n",
      "info_county           8763 non-null object\n",
      "info_parcel_number    8763 non-null int64\n",
      "taxes_land            8632 non-null float64\n",
      "taxes_improvements    8632 non-null float64\n",
      "taxes_total           8632 non-null float64\n",
      "taxes_taxes           8632 non-null object\n",
      "school                8763 non-null int64\n",
      "total_crime           8498 non-null float64\n",
      "violent_crime         8498 non-null float64\n",
      "property_crime        8498 non-null float64\n",
      "foreclosures          8763 non-null int64\n",
      "year_sold             8763 non-null int64\n",
      "dtypes: float64(12), int64(6), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_X_df` có `8763` dòng dữ liệu và `25` cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3756 entries, 1540 to 4911\n",
      "Data columns (total 25 columns):\n",
      "address_street        3749 non-null object\n",
      "address_locality      3756 non-null object\n",
      "address_region        3756 non-null object\n",
      "address_code          3756 non-null int64\n",
      "date_sold             3756 non-null object\n",
      "mortgage              3756 non-null float64\n",
      "info_type             3756 non-null object\n",
      "info_bedrooms         3412 non-null float64\n",
      "info_bathrooms        3415 non-null float64\n",
      "info_size             3585 non-null float64\n",
      "info_lot_size         2553 non-null float64\n",
      "info_year_built       3472 non-null float64\n",
      "info_property_id      3756 non-null int64\n",
      "info_county           3756 non-null object\n",
      "info_parcel_number    3756 non-null int64\n",
      "taxes_land            3689 non-null float64\n",
      "taxes_improvements    3689 non-null float64\n",
      "taxes_total           3689 non-null float64\n",
      "taxes_taxes           3689 non-null object\n",
      "school                3756 non-null int64\n",
      "total_crime           3658 non-null float64\n",
      "violent_crime         3658 non-null float64\n",
      "property_crime        3658 non-null float64\n",
      "foreclosures          3756 non-null int64\n",
      "year_sold             3756 non-null int64\n",
      "dtypes: float64(12), int64(6), object(7)\n",
      "memory usage: 762.9+ KB\n"
     ]
    }
   ],
   "source": [
    "val_X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`val_X_df` có `3756` dòng dữ liệu và `25` cột."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Quan sát và lựa chọn dữ liệu bằng kiến thức cá nhân trên tập train (`train_X_df` và `train_y_sr`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Quan sát cột `address_street`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55105280/how-to-extract-apartment-from-address-in-pandas\n",
    "pat = r'^(?P<number>\\d+)?(?P<direction>.\\w(?= ))?(?P<street>.+(?=\\bapt|\\bunit)|.+(?=#)|.+)(?P<apt_unit>(?:\\bapt|\\bunit|#|).+)?'\n",
    "lower_address_street = train_X_df.address_street.str.lower()\n",
    "tmp = lower_address_street.str.extract(pat)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"street\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tmp[\"street\"].value_counts() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp[\"street\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo kết quả tìm kiếm trên internet (https://cartographic.info/usa/street/show.php?p=california&t=Orange%20County) thì có `280` tên đường lớn tại `Orange County`. Vậy trong danh sách mà nhóm parse được có đến `6051` tên đường khác nhau, chắc bao gồm những con đường nhỏ. Việc dùng `street` cho huấn luyện mô hình sẽ không hiệu quả, vì khi đưa vào mô hình bằng phương pháp one-hot chắc chắn sẽ tạo ra số chiều rất lớn và với một số địa chỉ xuất hiện rất ít dễ dẫn đén overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp[pd.notna(tmp[\"apt_unit\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhóm sẽ xóa cột `address_street` và thêm cột `apt_unit` được rút trích ở trên vào dữ liệu ở bước tiền xử lý dữ liệu, cột này chỉ có 2 giá trị (`True`/`False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Quan sát các cột `address_locality`, `address_region` và `address_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Theo tìm hiểu của nhóm, `address_code` là tổng hợp từ `address_locality` và `address_region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_code = train_X_df.address_code.unique()\n",
    "len(unique_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92677    286\n",
       "92630    224\n",
       "92694    218\n",
       "92688    206\n",
       "90631    201\n",
       "92886    200\n",
       "92618    199\n",
       "92656    193\n",
       "92692    192\n",
       "92646    183\n",
       "92620    177\n",
       "92691    171\n",
       "92679    157\n",
       "92780    153\n",
       "92833    152\n",
       "92648    150\n",
       "92627    150\n",
       "92660    146\n",
       "92672    143\n",
       "92805    141\n",
       "92804    140\n",
       "92649    137\n",
       "92705    137\n",
       "92869    136\n",
       "92629    133\n",
       "92673    131\n",
       "92807    131\n",
       "92870    127\n",
       "92683    126\n",
       "92708    126\n",
       "        ... \n",
       "92625     67\n",
       "90720     66\n",
       "92802     65\n",
       "92706     65\n",
       "90621     63\n",
       "90680     63\n",
       "92603     60\n",
       "92604     59\n",
       "92843     58\n",
       "92841     57\n",
       "92845     53\n",
       "92703     52\n",
       "92657     49\n",
       "90740     48\n",
       "92606     44\n",
       "92832     43\n",
       "92868     43\n",
       "92844     41\n",
       "92866     38\n",
       "90623     32\n",
       "92624     32\n",
       "92676     27\n",
       "92661     21\n",
       "92861     20\n",
       "92823     19\n",
       "92662     16\n",
       "92655      8\n",
       "92617      6\n",
       "90742      4\n",
       "92685      1\n",
       "Name: address_code, Length: 87, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.address_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in unique_code:\n",
    "    tmp_df = train_X_df[train_X_df.address_code == code]\n",
    "    print(\"Code: \" + str(code))\n",
    "    print(\"\\n + Locality: \" + str(tmp_df.address_locality.unique()))\n",
    "    print(\"\\n + Region: \" + str(tmp_df.address_region.unique()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo nhóm tìm hiểu thì mã `code` (`address_code`) kia là mã bưu điện, mã này có thể dùng cho nhiều `locality` ở gần nhau, do đó ta kết quả như ở trên là hoàn toàn bình thường. Giờ nhóm quyết định bỏ 2 cột `address_locality` và `addres_region`, chỉ giữ lại cột `address_code` là đủ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `address_code` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_code = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.address_code)])\n",
    "print(\"The number of missing values (column 'address_code'): \" + str(num_miss_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `address_code` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Quan sát cột `date_sold`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xem thử cột `date_sold` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_date_sold = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.date_sold)])\n",
    "print(\"The number of missing values (column 'date_sold'): \" + str(num_miss_date_sold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `date_sold` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rút trích thông tin từ cột `date_sold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.date_sold.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `date_sold` được ghi dưới dạng `MM/DD/YYYY`. Giờ nhóm sẽ rút trích `Month` từ `date_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month = train_X_df.date_sold.str[:2].astype(int)\n",
    "sorted(month.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sở dĩ không có tháng `12` là do thời gian lấy dữ liệu của nhóm là đầu tháng `12` nên trang web chưa cập nhật. Về sau ở bước `Xây dựng pipline tiền xử lý dữ liệu`, nhóm sẽ tiến hành xóa cột `date_sold`, thêm cột `Month` và muốn thử để nguyên `11` tháng huấn luyện tốt hơn hay chia ra thành `4` mùa tốt hơn bằng cách đặt thêm cờ hiệu `month_to_seasion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4709\n",
       "4    4017\n",
       "2      28\n",
       "1       9\n",
       "Name: date_sold, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cách chia month theo 4 mùa\n",
    "season = (month%12 + 3)//3\n",
    "season.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4. Quan sát cột `mortgage`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mortgage` là tiền cho thuê tính theo tháng của căn nhà khi chưa được bán, nó cũng gần gần để suy ra `sold_price` rồi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.mortgage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thử cột `mortgage` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_mortgage = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.mortgage)])\n",
    "print(\"The number of missing values (column 'mortgage'): \" + str(num_miss_mortgage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `mortgage` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhưng, nhóm lại phát hiện khi lấy `mortgage` nhân cho `220` sẽ ra con số rất gần với giá tiền của căn nhà, nhưng vậy phải xóa `mortgage` đi thì mới áp dụng các mô hình máy học để dự đoán giá nhà được."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5. Quan sát cột `info_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Quan sát các giá trị xuất hiện trong cột và số lượng tương ứng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X_df.info_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Single Family Residence                            5709\n",
       "Condominium                                        2399\n",
       "MISCELLANEOUS                                       326\n",
       "Multi-Family Dwellings                              230\n",
       "Contact Agent                                        70\n",
       "Miscellaneous Structures - Ranch, Farm Fixtures      10\n",
       "Residential - Vacant Land                             5\n",
       "Cooperative                                           4\n",
       "Miscellaneous (Residential)                           3\n",
       "Governmental / Public Use (general)                   3\n",
       "Miscellaneous (general)                               2\n",
       "Agricultural (unimproved) - Vacant Land               1\n",
       "Duplex (2 units, any combination)                     1\n",
       "Name: info_type, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.info_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có một số giá trị xuất hiện rất ít, nhóm thử dùng thêm tham số `num_top_type` để chọn ra các `info_type` xuất hiện nhiều lần; còn các giá trị nằm ngoài `num_top_type` nhóm sẽ cho là giá trị `Others`. (như `BT03-TienXuLy_ChongOverfit`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `address_type` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_type = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.info_type)])\n",
    "print(\"The number of missing values (column 'info_type'): \" + str(num_miss_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `info_type` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5. Quan sát cột `info_bedrooms` và cột `info_bathrooms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xem thử cột `info_bedrooms` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_bedrooms = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_bedrooms)])\n",
    "print(\"The number of missing values (column 'info_bedrooms'): \" + str(num_miss_bedrooms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_bedrooms` có `812` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bedrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bedrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bedrooms.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do là `bedrooms` và các giá trị của nó là số nguyên, nên nhóm dùng `most` để lắp đầy các giá trị thiếu cho cột `info_bedrooms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `info_bathrooms` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_bathrooms = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_bathrooms)])\n",
    "print(\"The number of missing values (column 'info_bathrooms'): \" + str(num_miss_bathrooms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_bathrooms` có `807` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bathrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bathrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bathrooms.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự nhóm cùng sẽ dùng `most` để lắp đầy các giá trị thiếu cho cột `info_bathrooms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6. Quan sát cột `info_size` và cột `info_lot_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xem thử cột `info_size` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_size= train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_size)])\n",
    "print(\"The number of missing values (column 'info_size'): \" + str(num_miss_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_size` có `402` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_size.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_X_df.info_size.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điền các giá trị thiếu bằng `mean`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `info_lot_size` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_lot_size= train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_lot_size)])\n",
    "print(\"The number of missing values (column 'info_size'): \" + str(num_miss_lot_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_size` có `2832` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_lot_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_lot_size.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_X_df.info_lot_size.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điền các giá trị thiếu bằng `mean`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.7. Quan sát cột `info_year_built`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thử cột `info_year_built` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values (column 'info_size'): 664\n"
     ]
    }
   ],
   "source": [
    "num_miss_year_built = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_year_built)])\n",
    "print(\"The number of missing values (column 'info_size'): \" + str(num_miss_year_built))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_year_built` có `664` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1972., 1951.,   nan, 1996., 1963., 1961., 2014., 2009., 1955.,\n",
       "       1980., 2010., 2005., 1969., 1954., 1971., 1995., 1973., 1975.,\n",
       "       1977., 1990., 1976., 1965., 1985., 1999., 1964., 1989., 1956.,\n",
       "       1988., 1993., 2001., 1982., 1979., 2004., 1946., 1991., 1998.,\n",
       "       1950., 1966., 1984., 1987., 1917., 2007., 1962., 1948., 2008.,\n",
       "       1959., 1997., 2006., 1960., 1957., 1974., 2003., 1925., 1958.,\n",
       "       1978., 1952., 1949., 1968., 1986., 1970., 2000., 2002., 1953.,\n",
       "       2012., 1916., 2013., 1945., 1967., 1920., 1994., 1981., 1933.,\n",
       "       1928., 1929., 1937., 1983., 1894., 1992., 1947., 2011., 1922.,\n",
       "       1939., 1904., 1942., 1932., 1935., 1910., 1921., 1941., 1938.,\n",
       "       1900., 1930., 1927., 1944., 1923., 1926., 1915., 1931., 1907.,\n",
       "       1936., 1914., 1908., 1924., 1940., 1912., 1899., 1934., 1919.,\n",
       "       1911., 1918., 1943., 1913.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.info_year_built.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1964.0    252\n",
       "1989.0    250\n",
       "1963.0    225\n",
       "1972.0    216\n",
       "1977.0    210\n",
       "1973.0    205\n",
       "1965.0    202\n",
       "1976.0    199\n",
       "1990.0    197\n",
       "1955.0    196\n",
       "1974.0    196\n",
       "1971.0    186\n",
       "1986.0    176\n",
       "1969.0    172\n",
       "1980.0    169\n",
       "1978.0    166\n",
       "1979.0    165\n",
       "1983.0    162\n",
       "1987.0    161\n",
       "1962.0    161\n",
       "1956.0    158\n",
       "1984.0    147\n",
       "1954.0    144\n",
       "1959.0    144\n",
       "1985.0    142\n",
       "1975.0    138\n",
       "1968.0    127\n",
       "1960.0    122\n",
       "2003.0    119\n",
       "1981.0    116\n",
       "         ... \n",
       "1937.0      8\n",
       "1940.0      7\n",
       "1936.0      7\n",
       "1921.0      7\n",
       "1926.0      7\n",
       "1941.0      6\n",
       "1939.0      5\n",
       "1931.0      4\n",
       "1944.0      4\n",
       "1915.0      4\n",
       "1914.0      4\n",
       "1942.0      4\n",
       "1932.0      3\n",
       "1912.0      3\n",
       "1910.0      3\n",
       "1933.0      3\n",
       "1908.0      2\n",
       "1916.0      2\n",
       "1917.0      2\n",
       "1907.0      2\n",
       "1904.0      2\n",
       "1934.0      2\n",
       "1894.0      1\n",
       "1919.0      1\n",
       "1943.0      1\n",
       "1900.0      1\n",
       "1911.0      1\n",
       "1918.0      1\n",
       "1899.0      1\n",
       "1913.0      1\n",
       "Name: info_year_built, Length: 111, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.info_year_built.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8099.000000\n",
       "mean     1976.009137\n",
       "std        17.817193\n",
       "min      1894.000000\n",
       "25%      1964.000000\n",
       "50%      1976.000000\n",
       "75%      1989.000000\n",
       "max      2014.000000\n",
       "Name: info_year_built, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.info_year_built.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhóm muốn thử để nguyên các năm mà căn nhà được xây vào huấn luyện là tốt hay chia ra thành khoảng thời gian như: trước 1900, từ 1900 đến 1949, từ 1950 đến 1999, từ 2000 trở về sau. Nhóm đặt cờ hiệu `year_to_period`, nếu là `True` thì chuyển thành các khoảng thời gian để huấn luyện, ngược lại vẫn để nguyên vào huấn luyện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.8. Quan sát các cột `info_property_id`, `info_county` và `info_parcel_number`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `info_property_id` là cột dạng số (numerical) - int64\n",
    "- `info_county` là cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical)\n",
    "- `info_parcel_number` là cột dạng số (numerical) - int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bỏ đi các cột này, vì 2 cột `info_property_id` và `info_parcel_number` ứng với mỗi dòng dữ liệu là hoàn toàn khác nhau; còn cột `info_county` thì có giá trị là `Orange County` (do dữ liệu thu thập của Quận Cam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.9. Quan sát các cột `taxes_land`, `taxes_improvements`, `taxes_total` và `taxes_taxes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các cột này đều là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_taxes = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.taxes_land)])\n",
    "print(\"The number of missing values (column 'taxes'): \" + str(num_miss_taxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có `131` giá trị thiếu cho mỗi cột `taxes_land`, `taxes_improvements`, `taxes_total` và `taxes_taxes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search cùng `address_code` thì lắp đầy các giá trị thiếu bằng `mean` của các `taxes` trong cùng `address_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giữ nguyên các cột `taxes_land`, `taxes_improvements` và bỏ cột `taxes_total`. Giải thích thêm ý nghĩa của các cột này:\n",
    "- Cột `taxes_land` là tiền cải thuế cải tạo đất mà mình phải đóng cho chính phủ.\n",
    "- Cột `taxes_improvements` là tiền mà mình phải trả do sử dụng các tiện ích của chính phủ (cắt cỏ, tiền rác, củng cố hàng rào,...)\n",
    "- Cột `taxes_total` là tổng của 2 cột trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với cột `taxes_taxes` thì nhóm sẽ rút trích số tiền phải trả trong cột này ra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.taxes_taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.taxes_taxes.str.extract(r'(\\d+)', expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.10. Quan sát cột `school` và cột `foreclosures`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các cột này đều là cột dạng số (numerical) - int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai cột này không có giá trị thiếu, nên được giữ nguyên để huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.school.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.foreclosures.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.11. Quan sát cột `total_crime`, `violent_crime` và `property_crime`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các cột này đều là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích về ý nghĩa của các cột này. Giá trị mà các cột `total_crime`, `violent_crime` và `property_crime` biểu diễn được tính theo % so với tỉ lệ tội phạm quốc gia. Ví dụ `total_crime = 79` thì ở đây tổng số tội phạm là `79%` so với toàn nước (`100%`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_crime = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.total_crime)])\n",
    "print(\"The number of missing values (column 'taxes'): \" + str(num_miss_crime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có `265` giá trị thiếu cho mỗi cột `total_crime`, `violent_crime` và `property_crime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.total_crime.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search cùng `address_code` thì lắp đầy các giá trị thiếu bằng `median` của các `crime` trong cùng `address_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.12. Quan sát `correct input` (`sold_price` của ` train_y_sr`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sr.sort_values().sort_index().plot(style='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Thiết kế pipeline tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cột `address_street`: \n",
    "    - Ở đây có 4 thông tin được rút trích (xem  phần `4.2.1. Quan sát cột address_street` ở trên):\n",
    "         + `number`: số nhà, thông tin này không cần thiết cho việc huấn luyện.\n",
    "         + `direction`: hướng (đông, tây, nam, bắc) của đường, thông tin này không cần thiết cho việc huấn luyện.\n",
    "         + `street`: tên đường, theo kết quả parse thì thu được đến 6051 tên đường lớn/nhỏ khác nhau. Nếu đưa tên đường này vào huấn luyện thì có 3 vấn đề: thứ nhất là nếu dùng one-hot để chuyển sang dạng số thì sẽ làm tăng số chiều dữ liệu lên rất nhiều (thêm đến trên 6000 thuộc tính), thứ hai do có khoảng 1500 tên đường chỉ xuất hiện duy nhất một lần trong `train_X_df`, còn các tên đường khác thì cũng có tần số xuất hiện khá thấp (cao nhất chỉ có 16 lần) nên nếu thêm vào huấn luyện có thể dẫn đến overfitting, thứ 3 là nếu như ở tập `validation` hay tập `test` mà có tên đường không nằm trong tập `train` thì cũng khó khăn để giải quyết. Nên nhóm quyết định không lấy thông tin `street` để huấn luyện.\n",
    "         + `apt_unit`: cho biết căn nhà có thuộc chung cư nào hay không, thông tin này nhóm nghĩ là cần thiết cho việc huấn luyện vì nghĩ giá nhà riêng sẽ có phần nào khác với các căn nhà thuộc các khu chung cư. Vì vậy, sẽ thêm cột `is_apt` vào để huấn luyện, cột này chỉ có 2 giá trị `0`/`1` (nếu thuộc chung cư thì `1`, ngược lại thì `0`).\n",
    "    - Tóm lại, các việc cần làm:\n",
    "        + Rút trích ra cột `is_apt` (như mô tả ở trên) và thêm vào dữ liệu.\n",
    "        + Xóa cột `address_street`.\n",
    "        + Không cần lắp đầy giá trị thiếu, mặc định thiếu là 0 (tức tìm không thấy chung cư trong địa chỉ).\n",
    "        + Đây là dữ liệu số, để nguyên vậy vào huấn luyện.\n",
    "         \n",
    "2. Xóa 2 cột `address_locality` và cột `address_region`, giữ lại cột `address_code` (lý do xem ở phần `4.2.2. Quan sát các cột address_locality, address_region và address_code` ở trên). Ở tập `train_X_df` thì không thấy dữ liệu thiếu, nếu thiếu dùng `most` để lấp đầy. Dùng one-hot để đưa vào huấn luyện.\n",
    "3. Cột `date_sold`: rút trích `month` ra (xem ở phần `4.2.3. Quan sát cột date_sold`), xóa cột `date_sold` và `year_sol`, thêm vào cột `time_sold` (là giá trị `month` vừa rút trích, đặt tên để tiện cho sau này có chuyển sang `season` hay không thôi). Ở tập `train_X_df` thì không thấy dữ liệu thiếu, nếu thiếu dùng `most` để lấp đầy. Bỏ vào huấn luyện dùng one-hot, nhớ là thử để nguyên `11` tháng huấn luyện tốt hơn hay chia ra thành `4` mùa tốt hơn bằng cách đặt thêm cờ hiệu `month_to_season`.\n",
    "4. Cột `mortgage`: nếu để nguyên huấn luyện dùng mô hình `Linear Regression` thì cho ra kết quả độ chính xác bất ngờ là `99.99%`, và sau khi thử tính toán một vài records thì nhóm phát hiện ra chỉ cần lấy `mortgage` nhân cho `200` thì ra con số rất gần với giá nhà (`sold_price`), vì có công thức sẵn khi có được số liệu `mortgage`. Như thế thì dự đoán gì nữa, nên nhóm quyết định xóa đi cột `mortgage`.\n",
    "5. Cột `info_type`: Có một số giá trị xuất hiện rất ít, nhóm thử dùng thêm tham số `num_top_types` để chọn ra các `info_type` xuất hiện nhiều lần; còn các giá trị nằm ngoài `num_top_types` nhóm sẽ cho là giá trị `Others`. (như `BT03-TienXuLy_ChongOverfit`). Ở tập `train_X_df` thì không thấy dữ liệu thiếu, nếu thiếu dùng `most` để lấp đầy. Đưa vào huấn luyện thì dùng one-hot.\n",
    "6. Hai cột `info_bedrooms` và `info_bathrooms`: lắp đầy giá trị thiều bằng `most`. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "7. Hai cột `info_size` và `info_lot_size`: dùng `KNN (n=5)` để lắp đầy giá trị thiếu. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "8. Cột `info_year_built` để nguyên vào huấn luyện hoặc chuyển thành các giai đoạn (trước 1900, từ 1900 đên trước 1950, từ 1950 đến trước 2000 và từ 2000 trở về sau) bằng tham số `year_to_period`, lắp đầy giá trị thiếu bằng `most`, đưa vào huấn luyện dùng `one-hot`.\n",
    "9. Xóa 3 cột` info_property_id`, `info_county` và `info_parcel_number` (lý do xem ở phần `4.2.9. Quan sát các cột info_property_id, info_county và info_parcel_number`).\n",
    "10. Các cột `taxes_land`, `taxes_improvements`, `taxes_total` và `taxes_taxes`: đầu tiên rút trích `taxes` cho cột `taxes_taxes`, thay bằng dữ liệu tìm được (xem ở phần `4.2.10. Quan sát các cột taxes_land, taxes_improvements và taxes_taxes`), nhớ xóa cột `taxes_total`. Điền các giá trị thiếu bằng `mean`. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "11. Giữ nguyên cột `school` và cột `foreclosures`. Nếu có giá trị thiếu thì điền bằng `median`. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "12. Các `total_crime`, `violent_crime` và `property_crime`: lắp đầy giá trị thiếu bằng `median`. Kiểu số, cứ bỏ thẳng vào huấn luyện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chuẩn hóa theo cách của thầy trong `BT03`.\n",
    "- Dùng mô hình `Linear Regression` để huấn luyện mô mình thử xem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class AddressProcessor dùng để xử lý các cột address_street, address_locality, address_region và address_code\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "class AddressProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Extract các thông tin (số nhà, hướng của đường, tên đường, tên chung cư) từ address_street.\n",
    "        pat = r'^(?P<number>\\d+)?(?P<direction>.\\w(?= ))?(?P<street>.+(?=\\bapt|\\bunit)|.+(?=#)|.+)(?P<apt_unit>(?:\\bapt|\\bunit|#|).+)?'\n",
    "        lower_address_street = X_df.address_street.str.lower()\n",
    "        street_parsed = lower_address_street.str.extract(pat)\n",
    "        \n",
    "        # Xóa các cột dùng nữa.\n",
    "        transformed_df = X_df.drop([\"address_street\", \"address_locality\", \"address_region\"], axis=1)\n",
    "        \n",
    "        # Chuyển cột address_code về dạng categorical\n",
    "        transformed_df[\"address_code\"] = transformed_df[\"address_code\"].astype(str)\n",
    "            \n",
    "        # Thêm cột is_apt vào DataFrame (1 là thuộc chung cư, 0 là không không thuộc chung cư).\n",
    "        transformed_df[\"is_apt\"] = street_parsed[\"apt_unit\"].notnull().astype(int)\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7285\n",
       "1    1478\n",
       "Name: is_apt, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST AddressProcessor\n",
    "ap = AddressProcessor()\n",
    "\n",
    "ap.transform(train_X_df).is_apt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class DateSoldProcessor dùng để xử lý các cột date_sold và year_sold.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "\n",
    "class DateSoldProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, month_to_season = True):\n",
    "        self.month_to_season = month_to_season\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Rút trích month từ date_sold.\n",
    "        month = X_df.date_sold.str[:2].astype(int)\n",
    "        \n",
    "        # Xóa các cột không dùng nữa.\n",
    "        transformed_df = X_df.drop([\"date_sold\", \"year_sold\"], axis=1)\n",
    "        \n",
    "        if (self.month_to_season == False):\n",
    "            # Thêm cột month vào DataFrame (để tên là time_sold cho tiện truy cập).\n",
    "            transformed_df[\"time_sold\"] = month\n",
    "        else:\n",
    "            # 1 là Đông (tháng 12, 1, 2)\n",
    "            # 2 là Xuân (tháng 3, 4, 5)\n",
    "            # 3 là Hạ (tháng 6, 7, 8)\n",
    "            # 4 là Thu (tháng 9, 10, 11)\n",
    "            season = ((month.astype(int)%12 + 3)//3).astype(str)\n",
    "            # Thêm cột season_sold vào DataFrame (để tên là time_sold cho tiện truy cập).\n",
    "            transformed_df[\"time_sold\"] = season\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     1719\n",
       "8     1707\n",
       "9     1593\n",
       "10    1356\n",
       "6     1283\n",
       "11    1068\n",
       "5       12\n",
       "4        9\n",
       "3        7\n",
       "2        5\n",
       "1        4\n",
       "Name: time_sold, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST DateSoldProcessor\n",
    "dsp = DateSoldProcessor(False)\n",
    "\n",
    "dsp.transform(train_X_df).time_sold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4709\n",
       "4    4017\n",
       "2      28\n",
       "1       9\n",
       "Name: time_sold, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST DateSoldProcessor\n",
    "dsp = DateSoldProcessor(True)\n",
    "\n",
    "dsp.transform(train_X_df).time_sold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class InfoTypeProcessor dùng để xử lý cột info_type.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "\n",
    "class InfoTypeProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_types=5):\n",
    "        self.num_top_types = num_top_types\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        info_type_col = X_df.info_type\n",
    "        \n",
    "        # Đếm các dạng type trong cột info_type\n",
    "        self.type_counts_ = info_type_col.value_counts()\n",
    "        types = list(map(re.escape, self.type_counts_.index))\n",
    "        \n",
    "        # Lấy ra top_type theo tham số num_top_types được truyền vào\n",
    "        self.top_types_ = types[:max(1, min(self.num_top_types, len(types)))]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Các cột không phải top_type được mặc định là \"Others\"\n",
    "        type_sr = X_df.info_type.str.extract(f'^({\"|\".join(self.top_types_)})$', expand=False).fillna(\"Others\")\n",
    "        \n",
    "        # Xóa đi cột info_type vì không dùng nữa.\n",
    "        transformed_df = X_df.drop([\"info_type\"], axis=1)\n",
    "        \n",
    "        # Thêm cột type vào DataFrame.\n",
    "        transformed_df[\"type\"] = type_sr\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Single Family Residence                            5709\n",
       "Condominium                                        2399\n",
       "MISCELLANEOUS                                       326\n",
       "Multi-Family Dwellings                              230\n",
       "Contact Agent                                        70\n",
       "Miscellaneous Structures - Ranch, Farm Fixtures      10\n",
       "Others                                                7\n",
       "Residential - Vacant Land                             5\n",
       "Cooperative                                           4\n",
       "Miscellaneous (Residential)                           3\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST InfoTypeProcessor\n",
    "itp = InfoTypeProcessor(num_top_types=9)\n",
    "\n",
    "itp.fit(train_X_df).transform(train_X_df).type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class YearBuiltProcessor dùng để xử lý cột info_year_built.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "\n",
    "class YearBuiltProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, year_to_period=True):\n",
    "        self.year_to_period = year_to_period\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        transformed_df = X_df\n",
    "        \n",
    "        # Lấy cột năm xây dựng ra.\n",
    "        year_built = transformed_df.info_year_built\n",
    "        time_built = year_built.astype(str)\n",
    "        \n",
    "        # Xóa đi các cột không cần thiết.\n",
    "        transformed_df = X_df.drop([\"info_year_built\"], axis=1)\n",
    "        \n",
    "        # Chuyển từ year sang khoảng thời gian.\n",
    "        if (self.year_to_period == True):\n",
    "            for i in year_built.index:\n",
    "                year = year_built[i]\n",
    "                if year < 1900:\n",
    "                    time_built[i] = \"Before1900\"\n",
    "                if year >= 1900 and year < 1950:\n",
    "                    time_built[i] = \"From1900ToBefore1950\"\n",
    "                if year >= 1950 and year < 2000:\n",
    "                    time_built[i] = \"From1950ToBefore2000\"\n",
    "                if year >= 2000:\n",
    "                    time_built[i] = \"After2000\"\n",
    "\n",
    "        \n",
    "        # Thêm cột time_built vào DataFrame.\n",
    "        transformed_df[\"time_built\"] = time_built\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "From1950ToBefore2000    6883\n",
       "After2000                879\n",
       "nan                      664\n",
       "From1900ToBefore1950     335\n",
       "Before1900                 2\n",
       "Name: time_built, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YearBuiltProcessor\n",
    "itp = YearBuiltProcessor(True)\n",
    "\n",
    "itp.fit(train_X_df).transform(train_X_df).time_built.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan       664\n",
       "1964.0    252\n",
       "1989.0    250\n",
       "1963.0    225\n",
       "1972.0    216\n",
       "1977.0    210\n",
       "1973.0    205\n",
       "1965.0    202\n",
       "1976.0    199\n",
       "1990.0    197\n",
       "1955.0    196\n",
       "1974.0    196\n",
       "1971.0    186\n",
       "1986.0    176\n",
       "1969.0    172\n",
       "1980.0    169\n",
       "1978.0    166\n",
       "1979.0    165\n",
       "1983.0    162\n",
       "1987.0    161\n",
       "1962.0    161\n",
       "1956.0    158\n",
       "1984.0    147\n",
       "1959.0    144\n",
       "1954.0    144\n",
       "1985.0    142\n",
       "1975.0    138\n",
       "1968.0    127\n",
       "1960.0    122\n",
       "2003.0    119\n",
       "         ... \n",
       "1937.0      8\n",
       "1926.0      7\n",
       "1936.0      7\n",
       "1921.0      7\n",
       "1940.0      7\n",
       "1941.0      6\n",
       "1939.0      5\n",
       "1944.0      4\n",
       "1915.0      4\n",
       "1931.0      4\n",
       "1942.0      4\n",
       "1914.0      4\n",
       "1933.0      3\n",
       "1932.0      3\n",
       "1912.0      3\n",
       "1910.0      3\n",
       "1916.0      2\n",
       "1904.0      2\n",
       "1934.0      2\n",
       "1908.0      2\n",
       "1907.0      2\n",
       "1917.0      2\n",
       "1943.0      1\n",
       "1899.0      1\n",
       "1911.0      1\n",
       "1918.0      1\n",
       "1919.0      1\n",
       "1913.0      1\n",
       "1900.0      1\n",
       "1894.0      1\n",
       "Name: time_built, Length: 112, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YearBuiltProcessor\n",
    "itp = YearBuiltProcessor(False)\n",
    "\n",
    "itp.fit(train_X_df).transform(train_X_df).time_built.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class TaxesProcessor dùng để xử lý các cột taxes_total và taxes_taxes.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "\n",
    "class TaxesProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Extract ra tiền thuế phải trả.\n",
    "        taxes = X_df.taxes_taxes.str.extract(r'(\\d+)', expand=False)\n",
    "        \n",
    "        # Xóa đi các cột không cần thiết.\n",
    "        transformed_df = X_df.drop([\"taxes_total\", \"taxes_taxes\"], axis=1)\n",
    "        \n",
    "        # Thêm cột taxes_taxes với giá trị mới extract được vào.\n",
    "        transformed_df[\"taxes_taxes\"] = taxes\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10555    16\n",
       "7259      8\n",
       "5026      7\n",
       "1014      6\n",
       "6076      6\n",
       "4875      6\n",
       "4127      6\n",
       "4973      6\n",
       "5753      5\n",
       "2749      5\n",
       "1310      5\n",
       "3634      5\n",
       "3688      5\n",
       "4986      5\n",
       "6540      5\n",
       "3759      5\n",
       "3011      5\n",
       "2669      5\n",
       "2545      5\n",
       "7190      5\n",
       "3606      5\n",
       "1152      5\n",
       "6029      5\n",
       "6791      4\n",
       "5901      4\n",
       "1244      4\n",
       "1034      4\n",
       "1029      4\n",
       "7286      4\n",
       "4356      4\n",
       "         ..\n",
       "1440      1\n",
       "12584     1\n",
       "21207     1\n",
       "3920      1\n",
       "7370      1\n",
       "1335      1\n",
       "2022      1\n",
       "848       1\n",
       "7377      1\n",
       "3031      1\n",
       "31087     1\n",
       "957       1\n",
       "6348      1\n",
       "8207      1\n",
       "4877      1\n",
       "16987     1\n",
       "9759      1\n",
       "35916     1\n",
       "2577      1\n",
       "6329      1\n",
       "5485      1\n",
       "12127     1\n",
       "6667      1\n",
       "4247      1\n",
       "11631     1\n",
       "12704     1\n",
       "8443      1\n",
       "6661      1\n",
       "4960      1\n",
       "2488      1\n",
       "Name: taxes_taxes, Length: 6348, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST InfoTypeProcessor\n",
    "tp = TaxesProcessor()\n",
    "\n",
    "tp.fit(train_X_df).transform(train_X_df).taxes_taxes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class ColumnDropper dùng để xóa các cột info_property_id, info_county, info_parcel_number và mortgage.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        return X_df.drop([\"info_property_id\", \"info_county\", \"info_parcel_number\", \"mortgage\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8763 entries, 10747 to 2732\n",
      "Data columns (total 21 columns):\n",
      "address_street        8736 non-null object\n",
      "address_locality      8763 non-null object\n",
      "address_region        8763 non-null object\n",
      "address_code          8763 non-null int64\n",
      "date_sold             8763 non-null object\n",
      "info_type             8763 non-null object\n",
      "info_bedrooms         7951 non-null float64\n",
      "info_bathrooms        7956 non-null float64\n",
      "info_size             8361 non-null float64\n",
      "info_lot_size         5931 non-null float64\n",
      "info_year_built       8099 non-null float64\n",
      "taxes_land            8632 non-null float64\n",
      "taxes_improvements    8632 non-null float64\n",
      "taxes_total           8632 non-null float64\n",
      "taxes_taxes           8632 non-null object\n",
      "school                8763 non-null int64\n",
      "total_crime           8498 non-null float64\n",
      "violent_crime         8498 non-null float64\n",
      "property_crime        8498 non-null float64\n",
      "foreclosures          8763 non-null int64\n",
      "year_sold             8763 non-null int64\n",
      "dtypes: float64(11), int64(4), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# TEST InfoTypeProcessor\n",
    "cd = ColumnDropper()\n",
    "\n",
    "cd.fit(train_X_df).transform(train_X_df).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ tạo một `pipeline` của bước tiền xử lý dữ liệu để gom tất cả các bước xử lý ở trên, thêm thao tác điền các giá trị thiếu như mô tả và tiến hành chuẩn hóa bằng cách trừ đi mean và chia cho độ lệch chuẩn của cột để giúp cho các thuật toán cực tiểu hóa như Gradient Descent, LBFGS, ... hội tụ nhanh hơn (dùng `StandardScaler` trong Sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cols = [\"info_size\", \"info_lot_size\"]\n",
    "most_frequent_cols = [\"info_bedrooms\", \"info_bathrooms\"]\n",
    "mean_cols = [\"taxes_land\", \"taxes_improvements\", \"taxes_taxes\"]\n",
    "median_cols = [\"school\", \"foreclosures\", \"total_crime\", \"violent_crime\", \"property_crime\"]\n",
    "cate_cols = [\"address_code\", \"type\", \"time_built\", \"time_sold\"]\n",
    "\n",
    "cate_pipeline = Pipeline([(\"most_frequent\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "column_transformer = ColumnTransformer([(\"knn\", KNNImputer(), knn_cols),\n",
    "                                        (\"most_frequent\", SimpleImputer(strategy=\"most_frequent\"), most_frequent_cols),\n",
    "                                        (\"mean\", SimpleImputer(strategy=\"mean\"), mean_cols),\n",
    "                                        (\"median\", SimpleImputer(strategy=\"median\"), median_cols),\n",
    "                                        (\"cate\", cate_pipeline, cate_cols)])\n",
    "\n",
    "\n",
    "preprocess_pipeline = Pipeline([(\"address\", AddressProcessor()),\n",
    "                                (\"date_sold\", DateSoldProcessor()),\n",
    "                                (\"info_type\", InfoTypeProcessor()),\n",
    "                                (\"year_built\", YearBuiltProcessor()),\n",
    "                                (\"col_dropper\", ColumnDropper()),\n",
    "                                (\"taxes\", TaxesProcessor()),\n",
    "                                (\"column_transformer\", column_transformer),\n",
    "                                (\"std_scaler\", StandardScaler(with_mean=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8763x114 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 139296 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST preprocess_pipeline\n",
    "preprocess_pipeline.fit_transform(train_X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Mô hình hóa dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ ta có các siêu tham số:\n",
    "- `month_to_season` của class `DateSoldProcessor()`, có 2 giá trị :\n",
    "   + `True`: yêu cầu chuyển từ tháng bán nhà sang bán nhà theo bốn mùa.\n",
    "   + `False`: để nguyên các tháng bán nhà.\n",
    "   + Giá trị mặc định lúc code là `True`.\n",
    "- `num_top_types` của class `InfoTypeProcessor()`, giá trị là số nguyên dương. Trong tập train có khoảng 13 loại type. Giờ mình chỉ thử tập giá trị sau [1, 3, 5, 7, 9, 11, 13]. Giá trị mặc định lúc code là `5`.\n",
    "- `year_to_period` của class `YearBuiltProcessor()`, có 2 giá trị :\n",
    "   + `True`: yêu cầu chuyển từ năm xây dựng nhà sang các khoảng thời gian xây nhà .\n",
    "   + `False`: để nguyên các năm xây nhà.\n",
    "   + Giá trị mặc định lúc code là `True`.\n",
    "   \n",
    "Vậy ta muốn thử tất cả các giá trị ở trên thì tốn `3` vòng lặp với `2x7x2` là `28` lần chạy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ ta thử với mô hình `Linear Regression` với đủ 3 bộ tham số trên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                          (\"regression\", LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With month_to_season = True, year_to_period = True and num_top_types = 1:\n",
      " + train_err: 76.30336150055886\n",
      " + train_err: 63.19642528441863\n",
      "With month_to_season = True, year_to_period = True and num_top_types = 3:\n",
      " + train_err: 73.19519307812502\n",
      " + train_err: 60.91786611163863\n",
      "With month_to_season = True, year_to_period = True and num_top_types = 5:\n",
      " + train_err: 72.59982377413813\n",
      " + train_err: 60.81209462939404\n",
      "With month_to_season = True, year_to_period = True and num_top_types = 7:\n",
      " + train_err: 70.94568352569252\n",
      " + train_err: 59.42398143194044\n",
      "With month_to_season = True, year_to_period = True and num_top_types = 9:\n",
      " + train_err: 70.9407730543621\n",
      " + train_err: 59.40595387313977\n",
      "With month_to_season = True, year_to_period = True and num_top_types = 11:\n",
      " + train_err: 70.9396428302866\n",
      " + train_err: 59.40439029226361\n",
      "With month_to_season = True, year_to_period = True and num_top_types = 13:\n",
      " + train_err: 70.93827199537559\n",
      " + train_err: 59.413561502329074\n",
      "With month_to_season = True, year_to_period = False and num_top_types = 1:\n",
      " + train_err: 75.8079132444767\n",
      " + train_err: 62.77578519721608\n",
      "With month_to_season = True, year_to_period = False and num_top_types = 3:\n",
      " + train_err: 72.5342947677832\n",
      " + train_err: 60.44900144117859\n",
      "With month_to_season = True, year_to_period = False and num_top_types = 5:\n",
      " + train_err: 71.91244113199915\n",
      " + train_err: 60.35725845651893\n",
      "With month_to_season = True, year_to_period = False and num_top_types = 7:\n",
      " + train_err: 70.14469367459515\n",
      " + train_err: 58.9032740245874\n",
      "With month_to_season = True, year_to_period = False and num_top_types = 9:\n",
      " + train_err: 70.13979304303797\n",
      " + train_err: 58.883577045370025\n",
      "With month_to_season = True, year_to_period = False and num_top_types = 11:\n",
      " + train_err: 70.13882278439827\n",
      " + train_err: 58.883133184677895\n",
      "With month_to_season = True, year_to_period = False and num_top_types = 13:\n",
      " + train_err: 70.13803185859246\n",
      " + train_err: 58.89016784040875\n",
      "With month_to_season = False, year_to_period = True and num_top_types = 1:\n",
      " + train_err: 76.10452874608998\n",
      " + train_err: 62.952424228964546\n",
      "With month_to_season = False, year_to_period = True and num_top_types = 3:\n",
      " + train_err: 72.98787326093631\n",
      " + train_err: 60.68029759571483\n",
      "With month_to_season = False, year_to_period = True and num_top_types = 5:\n",
      " + train_err: 72.39772308376402\n",
      " + train_err: 60.5903808223808\n",
      "With month_to_season = False, year_to_period = True and num_top_types = 7:\n",
      " + train_err: 70.74686151337373\n",
      " + train_err: 59.20104338256195\n",
      "With month_to_season = False, year_to_period = True and num_top_types = 9:\n",
      " + train_err: 70.74069563389153\n",
      " + train_err: 59.18090480109374\n",
      "With month_to_season = False, year_to_period = True and num_top_types = 11:\n",
      " + train_err: 70.74006320095884\n",
      " + train_err: 59.17971535814955\n",
      "With month_to_season = False, year_to_period = True and num_top_types = 13:\n",
      " + train_err: 70.73875196652953\n",
      " + train_err: 59.18860614206615\n",
      "With month_to_season = False, year_to_period = False and num_top_types = 1:\n",
      " + train_err: 75.60732170158576\n",
      " + train_err: 62.530198585394864\n",
      "With month_to_season = False, year_to_period = False and num_top_types = 3:\n",
      " + train_err: 72.3307405057688\n",
      " + train_err: 60.21328113744065\n",
      "With month_to_season = False, year_to_period = False and num_top_types = 5:\n",
      " + train_err: 71.71591551386841\n",
      " + train_err: 60.13838200323697\n",
      "With month_to_season = False, year_to_period = False and num_top_types = 7:\n",
      " + train_err: 69.95088077362666\n",
      " + train_err: 58.684447730280176\n",
      "With month_to_season = False, year_to_period = False and num_top_types = 9:\n",
      " + train_err: 69.94469448309016\n",
      " + train_err: 58.662585075855304\n",
      "With month_to_season = False, year_to_period = False and num_top_types = 11:\n",
      " + train_err: 69.94418072635936\n",
      " + train_err: 58.66253800275205\n",
      "With month_to_season = False, year_to_period = False and num_top_types = 13:\n",
      " + train_err: 69.94343623779702\n",
      " + train_err: 58.66924741807093\n"
     ]
    }
   ],
   "source": [
    "month_to_season_s = [True, False]\n",
    "year_to_period_s = [True, False]\n",
    "num_top_types_s = [1, 3, 5, 7, 9, 11, 13]\n",
    "\n",
    "best_val_err_LR = float('inf')\n",
    "best_month_to_season_LR = True\n",
    "best_year_to_period_LR = True\n",
    "best_num_top_types_LR = 0\n",
    "\n",
    "train_errs = []\n",
    "val_errs = []\n",
    "\n",
    "for month_to_season in month_to_season_s:\n",
    "    for year_to_period in year_to_period_s:\n",
    "        for num_top_types in num_top_types_s:\n",
    "            # Set các tham số mới cho full_pipeline\n",
    "            full_pipeline.set_params(preprocess__date_sold__month_to_season=month_to_season,\n",
    "                                     preprocess__year_built__year_to_period=year_to_period,\n",
    "                                     preprocess__info_type__num_top_types=num_top_types)\n",
    "            \n",
    "            # Fit full_pipeline vào tập huấn luyện\n",
    "            full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    \n",
    "            # Độ lỗi trên tập huấn luyện\n",
    "            train_err = 100 - full_pipeline.score(train_X_df, train_y_sr)*100\n",
    "    \n",
    "            # Độ lỗi tên tập validation\n",
    "            val_err = 100 - full_pipeline.score(val_X_df, val_y_sr)*100\n",
    "        \n",
    "            # Lưu lại các giá trị độ lỗi\n",
    "            train_errs.append(train_err)\n",
    "            val_errs.append(val_err)\n",
    "        \n",
    "            # Lưu lại best_val_err, best_alpha, best_num_top_titles\n",
    "            if (val_err < best_val_err_LR): \n",
    "                best_val_err_LR = val_err\n",
    "                best_month_to_season_LR = month_to_season\n",
    "                best_year_to_period_LR = year_to_period\n",
    "                best_num_top_types_LR = num_top_types\n",
    "            \n",
    "            print(\"With month_to_season = \" + str(month_to_season) + \", year_to_period = \" + str(year_to_period) + \" and num_top_types = \" + str(num_top_types) + (\":\"))\n",
    "            print(\" + train_err: \" + str(train_err))\n",
    "            print(\" + train_err: \" + str(val_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + error_train: 72.59982377413813\n",
      " + error_validation: 60.81209462939404\n"
     ]
    }
   ],
   "source": [
    "full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                          (\"regression\", LinearRegression())])\n",
    "error_val_LR = 0\n",
    "\n",
    "full_pipeline.fit(train_X_df, train_y_sr)\n",
    "error_train = 100 - full_pipeline.score(train_X_df, train_y_sr)*100\n",
    "error_val = 100 - full_pipeline.score(val_X_df, val_y_sr)*100\n",
    "\n",
    "print(\" + error_train: \" + str(error_train))\n",
    "print(\" + error_validation: \" + str(error_val))\n",
    "\n",
    "error_val_LR = error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. K-Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With n_neighbors = 1\n",
      " + error_train: 0.0063873032629828685\n",
      " + error_validation: 19.273275573141476\n",
      "With n_neighbors = 3\n",
      " + error_train: 9.216409482344247\n",
      " + error_validation: 22.390799449197985\n",
      "With n_neighbors = 5\n",
      " + error_train: 15.746979819901469\n",
      " + error_validation: 24.075030658647194\n",
      "With n_neighbors = 7\n",
      " + error_train: 20.548737920453206\n",
      " + error_validation: 27.83458256385201\n",
      "With n_neighbors = 9\n",
      " + error_train: 24.798967675236\n",
      " + error_validation: 35.51147013092999\n",
      "With n_neighbors = 11\n",
      " + error_train: 29.62675159815747\n",
      " + error_validation: 41.96661525705745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neighbors = [1, 3, 5, 7, 9, 11]\n",
    "best_neighbors_KNR = 0\n",
    "best_error_val_KNR = float('inf')\n",
    "\n",
    "for n in neighbors:\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"regression\", KNeighborsRegressor(n_neighbors=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    error_train = 100 - full_pipeline.score(train_X_df, train_y_sr)*100\n",
    "    error_val = 100 - full_pipeline.score(val_X_df, val_y_sr)*100\n",
    "    \n",
    "    print(\"With n_neighbors = \" + str(n))\n",
    "    print(\" + error_train: \" + str(error_train))\n",
    "    print(\" + error_validation: \" + str(error_val))\n",
    "    \n",
    "    if error_val < best_error_val_KNR:\n",
    "        best_error_val_KNR = error_val\n",
    "        best_neighbors_KNR = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.353580744925836\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(best_error_val_KNR)\n",
    "print(best_neighbors_KNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With depth = 3\n",
      " + error_train: 12.406133612238222\n",
      " + error_validation: 23.203666054237942\n",
      "With depth = 4\n",
      " + error_train: 9.00411887365793\n",
      " + error_validation: 9.028294568910724\n",
      "With depth = 5\n",
      " + error_train: 6.4189425491449725\n",
      " + error_validation: 9.99414834080676\n",
      "With depth = 6\n",
      " + error_train: 5.02856337636311\n",
      " + error_validation: 9.008873875653336\n",
      "With depth = 7\n",
      " + error_train: 4.2441991986717085\n",
      " + error_validation: 9.567176508519736\n",
      "With depth = 8\n",
      " + error_train: 3.132866357860081\n",
      " + error_validation: 20.238078207975022\n",
      "With depth = 9\n",
      " + error_train: 1.6403510936901\n",
      " + error_validation: 5.472689223182272\n",
      "With depth = 10\n",
      " + error_train: 0.46246347595740644\n",
      " + error_validation: 8.66620489072983\n",
      "With depth = 11\n",
      " + error_train: 0.26130094845004237\n",
      " + error_validation: 7.410907835735188\n",
      "With depth = 12\n",
      " + error_train: 0.13000659462885267\n",
      " + error_validation: 9.475003520655761\n",
      "With depth = 13\n",
      " + error_train: 0.08074241766722423\n",
      " + error_validation: 21.290496243095276\n",
      "With depth = 14\n",
      " + error_train: 0.05112497496294566\n",
      " + error_validation: 20.992226419423105\n",
      "With depth = 15\n",
      " + error_train: 0.03574047239349909\n",
      " + error_validation: 9.925735077654082\n",
      "With depth = 16\n",
      " + error_train: 0.028184824603997072\n",
      " + error_validation: 8.328102295044914\n",
      "With depth = 17\n",
      " + error_train: 0.022910448175579745\n",
      " + error_validation: 7.563935462077737\n",
      "With depth = 18\n",
      " + error_train: 0.017466449050445476\n",
      " + error_validation: 8.647744808994588\n",
      "With depth = 19\n",
      " + error_train: 0.013963163761161468\n",
      " + error_validation: 7.4995643098504985\n",
      "With depth = 20\n",
      " + error_train: 0.011499468831488002\n",
      " + error_validation: 7.841240243869507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "best_depth_DTR = 0\n",
    "best_error_val_DTR = float('inf')\n",
    "\n",
    "for depth in range(3,21):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"regression\", DecisionTreeRegressor(random_state=0, max_depth = depth))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    error_train = 100 - full_pipeline.score(train_X_df, train_y_sr)*100\n",
    "    error_val = 100 - full_pipeline.score(val_X_df, val_y_sr)*100\n",
    "    \n",
    "    print(\"With depth = \" + str(depth))\n",
    "    print(\" + error_train: \" + str(error_train))\n",
    "    print(\" + error_validation: \" + str(error_val))\n",
    "    \n",
    "    if error_val < best_error_val_DTR:\n",
    "        best_error_val_DTR = error_val\n",
    "        best_depth_DTR = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.51533105213325\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(best_error_val_DTR)\n",
    "print(best_depth_DTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With depth = 3\n",
      " + error_train: 27.357733951800313\n",
      " + error_validation: 33.40560567890043\n",
      "With depth = 4\n",
      " + error_train: 11.395160154922834\n",
      " + error_validation: 22.20369392903494\n",
      "With depth = 5\n",
      " + error_train: 7.040905526446693\n",
      " + error_validation: 16.20691294342295\n",
      "With depth = 6\n",
      " + error_train: 5.401936889743624\n",
      " + error_validation: 18.948915126942254\n",
      "With depth = 7\n",
      " + error_train: 4.219666164873033\n",
      " + error_validation: 17.025089033221434\n",
      "With depth = 8\n",
      " + error_train: 3.4165800096000822\n",
      " + error_validation: 18.97828583111456\n",
      "With depth = 9\n",
      " + error_train: 3.4613522661269513\n",
      " + error_validation: 18.182043658340646\n",
      "With depth = 10\n",
      " + error_train: 3.0970170426747785\n",
      " + error_validation: 12.85855351482111\n",
      "With depth = 11\n",
      " + error_train: 3.257622311784843\n",
      " + error_validation: 19.545079158780965\n",
      "With depth = 12\n",
      " + error_train: 3.738245539402598\n",
      " + error_validation: 18.622801473309607\n",
      "With depth = 13\n",
      " + error_train: 3.1263995582746844\n",
      " + error_validation: 15.961045558380377\n",
      "With depth = 14\n",
      " + error_train: 3.217222750061339\n",
      " + error_validation: 15.752513214962065\n",
      "With depth = 15\n",
      " + error_train: 3.4816293161772194\n",
      " + error_validation: 20.87676902676877\n",
      "With depth = 16\n",
      " + error_train: 3.207720540759425\n",
      " + error_validation: 13.1065468784318\n",
      "With depth = 17\n",
      " + error_train: 4.0665884452961905\n",
      " + error_validation: 21.64716221150654\n",
      "With depth = 18\n",
      " + error_train: 3.6379569902116202\n",
      " + error_validation: 12.37721216271919\n",
      "With depth = 19\n",
      " + error_train: 3.166524489327898\n",
      " + error_validation: 19.49082246246195\n",
      "With depth = 20\n",
      " + error_train: 2.6448982924525097\n",
      " + error_validation: 16.907123806935417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "best_depth_RFR = 0\n",
    "best_error_val_RFR = float('inf')\n",
    "\n",
    "for depth in range(3,21):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"regression\", RandomForestRegressor(n_estimators=10, random_state=0, max_depth=depth))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    error_train = 100 - full_pipeline.score(train_X_df, train_y_sr)*100\n",
    "    error_val = 100 - full_pipeline.score(val_X_df, val_y_sr)*100\n",
    "    \n",
    "    print(\"With depth = \" + str(depth))\n",
    "    print(\" + error_train: \" + str(error_train))\n",
    "    print(\" + error_validation: \" + str(error_val))\n",
    "    \n",
    "    if error_val < best_error_val_RFR:\n",
    "        best_error_val_RFR = error_val\n",
    "        best_depth_RFR = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.37721216271919\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(best_error_val_RFR)\n",
    "print(best_depth_RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
