{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thông tin nhóm 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1612406 - Đặng Phương Nam\n",
    "\n",
    "1612423 - Lê Minh nghĩa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Câu hỏi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cho các thông tin về căn nhà:\n",
    "\n",
    "- Giá cho thuê trước khi bán.\n",
    "- Địa chỉ.\n",
    "- Loại nhà.\n",
    "- Số phòng ngủ.\n",
    "- Số nhà vệ sinh.\n",
    "- Diện tích phần nhà.\n",
    "- Diện tích toàn bộ lô đất.\n",
    "- Năm xây dựng.\n",
    "- Tiền thuế.\n",
    "- Gần mấy trường học.\n",
    "- Tình hình tội phạm.\n",
    "- ...\n",
    "\n",
    "Hỏi giá trị của căn nhà là bao nhiêu tiền?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lợi ích khi trả lời được câu hỏi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhờ vào thông tin của căn nhà:\n",
    "\n",
    "- Người bán có thể dự đoán được giá trị căn nhà mà mình muốn bán.\n",
    "- Người mua có thể ước lượng được căn nhà mình muốn mua có giá cả hợp lý hay không?.\n",
    "- Dự đoán được giá trị căn nhà của mình.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 3. Thu thập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Parse HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu thu thập từ trang web https://www.realtytrac.com/. Ta chỉ thu thập dữ liệu \"các estate đã được bán tại  California\", ta có HTML cần parse: https://m.realtytrac.com/mapsearch/sold/ca/\n",
    "\n",
    "Thời gian lấy dữ liệu: Ngày 10/12/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết.\n",
    "import urllib.robotparser\n",
    "import json\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('https://m.realtytrac.com/robots.txt')\n",
    "rp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy link chứa danh sách các ngôi nhà đã bán theo Quận tại California\n",
    "check_parse = rp.can_fetch('*', 'https://m.realtytrac.com/mapsearch/sold/ca/')\n",
    "\n",
    "base_url = \"https://m.realtytrac.com\"\n",
    "list_url_county = []\n",
    "\n",
    "# Kiểm tra việc parse HTML được cho phép hay không?\n",
    "if check_parse == True:\n",
    "    session = HTMLSession()\n",
    "    r = session.get('https://m.realtytrac.com/mapsearch/sold/ca/')\n",
    "\n",
    "    counties = r.html.find(\"option\")\n",
    "\n",
    "    for county in counties:\n",
    "        tail_url = county.attrs['value']\n",
    "        if (tail_url):\n",
    "            url = base_url + tail_url\n",
    "            list_url_county.append(url)\n",
    "\n",
    "\n",
    "list_url_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm trả về generator, generator này trả về trang tiếp theo sau mỗi lần duyệt.\n",
    "def urlGenerator(baseUrl, startPage=1):\n",
    "    i = startPage\n",
    "    if i <= 1:\n",
    "        yield baseUrl\n",
    "        i = 2\n",
    "    while True:\n",
    "        yield f\"{baseUrl}/p-{i}\"\n",
    "        i += 1\n",
    "\n",
    "\n",
    "# Hàm parseDetailPage: parse để lấy thông tin chi tiết của từng căn nhà từ detailUrl (của căn nhà đã bán).\n",
    "# Tham số: session và detailUrl của căn nhà cần parse.\n",
    "# Trả về: dictionary chứa các thông tin đã parse được.\n",
    "def parseDetailPage(session: HTMLSession, detailUrl: str):\n",
    "\n",
    "    # Lấy mã HTML của trang web.\n",
    "    r = session.get(detailUrl)\n",
    "\n",
    "    # Dictionary lưu lại kết quả.\n",
    "    result = {}\n",
    "\n",
    "    # Lấy address của estate.\n",
    "    address = {}\n",
    "    street = r.html.find(\"[itemprop = 'streetAddress']\", first=True)\n",
    "    if street is not None:\n",
    "        street = street.text\n",
    "\n",
    "    locality = r.html.find(\"[itemprop = 'addressLocality']\", first=True)\n",
    "    if locality is not None:\n",
    "        locality = locality.text\n",
    "\n",
    "    region = r.html.find(\"[itemprop = 'addressRegion']\", first=True)\n",
    "    if region is not None:\n",
    "        region = region.text\n",
    "\n",
    "    code = r.html.find(\"[itemprop = 'postalCode']\", first=True)\n",
    "    if code is not None:\n",
    "        code = code.text\n",
    "\n",
    "    address[\"street\"] = street\n",
    "    address[\"locality\"] = locality\n",
    "    address[\"region\"] = region\n",
    "    address[\"code\"] = code\n",
    "\n",
    "    result[\"address\"] = address\n",
    "\n",
    "    # Lấy thông tin ngày đã bán căn nhà.\n",
    "    date_sold = r.html.find(\".recently-sold\", first=True)\n",
    "    if date_sold is not None:\n",
    "        result[\"date_sold\"] = date_sold.text.replace(\"SOLD ON \", \"\")\n",
    "    else:\n",
    "        result[\"date_sold\"] = None\n",
    "\n",
    "    # Lấy giá cho thuê trước khi bán.\n",
    "    mortgage = r.html.find(\".property-price-info\", first=True)\n",
    "    if mortgage is not None:\n",
    "        result[\"mortgage\"] = mortgage.text.replace(\"Est. Mortgage: \",\"\")\n",
    "    else:\n",
    "        result[\"mortgage\"] = None\n",
    "\n",
    "\n",
    "    # Lấy phân mô tả chi tiết về căn nhà.\n",
    "    details = []\n",
    "    detailTexts = r.html.find(\".detail-text\")\n",
    "    if detailTexts is not None:\n",
    "        for detailText in detailTexts:\n",
    "            details.append(detailText.html)  # sở dĩ lấy mà HTML để dễ parse sau này (khi muốn lấy thông tin từ details)\n",
    "    result[\"details\"] = details\n",
    "\n",
    "    # Lấy property info của căn nhà.\n",
    "    propertyInfo = r.html.find(\".property-info\", first=True)\n",
    "    if propertyInfo is not None:\n",
    "        info = {}\n",
    "        items = propertyInfo.find(\".item\")\n",
    "        if items is not None:\n",
    "            for item in items:\n",
    "                name = item.find(\".name\", first=True).text.lower().replace(\" \", \"_\")\n",
    "                value = item.find(\".value\", first=True).text\n",
    "                info[name] = value\n",
    "\n",
    "        result[\"info\"] = info\n",
    "    else:\n",
    "        result[\"info\"] = None\n",
    "\n",
    "    # Lấy property taxes của căn nhà.\n",
    "    property_taxes = r.html.find(\".property-taxes\")\n",
    "    if property_taxes is not None:\n",
    "        for tax in property_taxes:\n",
    "            key = tax.find(\".section-head\", first=True).text.lower().replace(\" \", \"_\")\n",
    "            taxes = {}\n",
    "            items = tax.find(\".item\")\n",
    "            if items is not None:\n",
    "                for item in items:\n",
    "                    name = item.find(\".name\", first=True).text.lower().replace(\" \", \"_\")\n",
    "                    value = item.find(\".value\", first=True).text\n",
    "                    taxes[name] = value\n",
    "\n",
    "            result[key] = taxes\n",
    "\n",
    "    # Lấy số lượng trường học gần đó.\n",
    "    local_school = r.html.find(\".property-schools\", first=True)\n",
    "    num_school = 0\n",
    "    if local_school is not None:\n",
    "        num_school = len(local_school.find(\".schoolInfo\"))\n",
    "\n",
    "    result[\"school\"] = num_school\n",
    "\n",
    "    # Lấy thông tin tội phạm trong vùng.\n",
    "    crimes = {}\n",
    "    local_crime_index = r.html.find(\".property-local-crime\", first=True)\n",
    "    if local_crime_index is not None:\n",
    "        type_crimes = local_crime_index.find(\".gradeTitle\")\n",
    "        if type_crimes is not None:\n",
    "            for type_crime in type_crimes:\n",
    "                match = re.match(r\"(.+?) = (\\d+)\", type_crime.text)\n",
    "                if match is not None:\n",
    "                    key = match.group(1).lower().replace(' ', '_')\n",
    "                    value = int(match.group(2))\n",
    "                    crimes[key] = value\n",
    "\n",
    "    result[\"local_crime_index\"] = crimes\n",
    "\n",
    "    # Lấy số lượng nhà bị tịch thu gần đó.\n",
    "    nearby_foreclosures = r.html.find(\".property-nearby-fc\", first=True)\n",
    "    num_fc = 0\n",
    "    if nearby_foreclosures is not None:\n",
    "        num_fc = len(nearby_foreclosures.find(\".nearby-property\"))\n",
    "\n",
    "    result[\"foreclosures\"] = num_fc\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm parseSearchPage: parse theo page (mỗi parse chứa danh sách và url của 25 căn nhà đã được bán).\n",
    "# Tham số: session và url của page hiện tại.\n",
    "# Trả về: list thông tin chi tiết của tất cả căn nhà tại page hiện tại và url của page kế tiếp.\n",
    "def parseSearchPage(session: HTMLSession, urlPage: str):\n",
    "\n",
    "    # Lấy mã HTML.\n",
    "    r = session.get(urlPage)\n",
    "\n",
    "    # Lấu detailUrl của tất cả bất động sản.\n",
    "    detailUrls = [link for link in r.html.absolute_links if 'property' in link]\n",
    "\n",
    "    results = []  # List chứa kết quả parse được tại page.\n",
    "\n",
    "    # Tiến hành parse từ detailUrl\n",
    "    for detailUrl in detailUrls:\n",
    "        # Kiểm tra việc parse HTML được cho phép hay không?\n",
    "        if not rp.can_fetch('*', detailUrl):\n",
    "            print(f\"SKIP: {detailUrl}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Parsing detail url {detailUrl}\")\n",
    "        result = parseDetailPage(session, detailUrl)\n",
    "        results.append(result)\n",
    "\n",
    "    nextPageAnchor = r.html.find(\".current + .page\", first=True)\n",
    "    return results, nextPageAnchor is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm getAllCountyProperties: parse tất cả các page của một County để lấy thông tin chi tiết của \n",
    "# căn nhà được bán thành công.\n",
    "# Tham số: session và countryUrl chứa thông tin các căn nhà được bán của một County.\n",
    "# Trả về: File chứa kết quả đã parse thành công (tên file là tên County được parse).\n",
    "def getAllCountyProperties(session: HTMLSession, countyUrl: str):\n",
    "    # Lấy tên County từ urlCounty.\n",
    "    if countyUrl.endswith(\"/\"):\n",
    "        countyUrl = countyUrl[:-1]\n",
    "    fileName = f\"data/{os.path.basename(countyUrl)}.json\"\n",
    "\n",
    "    # Kiểm tra sự tồn tại file.\n",
    "    if os.path.exists(fileName):\n",
    "        print(f\"FILE EXISTS: {fileName}\")\n",
    "        return\n",
    "\n",
    "    # Mở file để ghi dữ liệu (kiểu file là json)\n",
    "    with open(fileName, \"a\") as fOut:\n",
    "        for url in urlGenerator(countyUrl, 1):\n",
    "            # Kiểm tra việc parse HTML được cho phép hay không?\n",
    "            if not rp.can_fetch('*', url):\n",
    "                print(f\"SKIP: {url}\")\n",
    "                continue\n",
    "\n",
    "            # Tiến hành parse theo từng page.\n",
    "            print(f\"Parsing {url}\")\n",
    "            results, nextPage = parseSearchPage(session, url)\n",
    "\n",
    "            # Ghi kết quả xuống file.\n",
    "            for result in results:\n",
    "                json.dump(result, fOut, ensure_ascii=False)\n",
    "                fOut.write(\"\\n\")\n",
    "\n",
    "            # Kiểm tra có còn page tiếp theo hay không?\n",
    "            if not nextPage:\n",
    "                break\n",
    "\n",
    "            # Mỗi lần parse 1 page thì cho sleep 2s.\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiến hành lấy dữ liệu. Lưu ý trong quá trình lấy có thể bị timeout do đường truyền mạng, nếu bị thì chỉ cần làm theo các bước sau:\n",
    "- Xem đã lấy tới page mấy. vd: \"...page-125\"\n",
    "- Đổi lại tên file trong thư mục data là \"orange-county-1.json\" chẳng hạn (số 1, 2, 3,.. là theo mỗi lần lấy dữ liệu của mình).\n",
    "- Vào hàm \"getAllCountyProperties\" đổi lại dòng \"for url in urlGenerator(countyUrl, 1)\" thành \"for url in urlGenerator(countyUrl, 125)\", số 125 là tùy mình lấy tới page thứ mấy mà bị timeout.\n",
    "- Dữ liệu tất nhiên sẽ bi trùng, cứ việc yên tâm vì phần sau sẽ xóa trung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://m.realtytrac.com/mapsearch/sold/ca/orange-county\"\n",
    "session = HTMLSession()\n",
    "getAllCountyProperties(session, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần gộp từng phần dữ liệu đã lấy dang dở lại thành 1 file.\n",
    "# Nếu không bị timeout như trường hợp ở trên thì không dùng shell code này.\n",
    "inputFiles = [\"data/orange-county-1.json\", \"data/orange-county-2.json\", \n",
    "              \"data/orange-county-3.json\", \"data/orange-county-4.json\"]\n",
    "outputFile = \"data/full-orange-county.json\"\n",
    "\n",
    "with open(outputFile, \"a+\") as fOut:\n",
    "    for inputFile in inputFiles:\n",
    "        with open(inputFile, \"r\") as fIn:\n",
    "            data = fIn.read()\n",
    "            fOut.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần convert file json sang file csv.\n",
    "\n",
    "def xstr(s):\n",
    "    return '' if s is None else str(s)\n",
    "\n",
    "\n",
    "# Hàm preprocessFile: chuyển file json sang file csv.\n",
    "# Tham số: tên file json và tên file csv.\n",
    "# Không trả về.\n",
    "def preprocessFile(inputFile: str, outputFile: str):\n",
    "\n",
    "    # Kiểm tra tồn tại file Input.\n",
    "    if os.path.exists(outputFile):\n",
    "        print(f\"FILE EXISTS: {outputFile}\")\n",
    "        return\n",
    "\n",
    "    # Kiểm tra tồn tại file Output.\n",
    "    if not os.path.exists(inputFile):\n",
    "        print(f\"Input file not found: {inputFile}\")\n",
    "        return\n",
    "\n",
    "    with open(inputFile) as fIn, open(outputFile, \"w\") as fOut:\n",
    "        tab = \"\\t\"\n",
    "        headers = (\n",
    "            \"address_street\",\n",
    "            \"address_locality\",\n",
    "            \"address_region\",\n",
    "            \"address_code\",\n",
    "            \"date_sold\",\n",
    "            \"mortgage\",\n",
    "            \"info_type\",\n",
    "            \"info_bedrooms\",\n",
    "            \"info_bathrooms\",\n",
    "            \"info_size\",\n",
    "            \"info_lot_size\",\n",
    "            \"info_year_built\",\n",
    "            \"info_est_value\",\n",
    "            \"info_sold_price\",\n",
    "            \"info_property_id\",\n",
    "            \"info_county\",\n",
    "            \"info_parcel_number\",\n",
    "            \"taxes_land\",\n",
    "            \"taxes_improvements\",\n",
    "            \"taxes_total\",\n",
    "            \"taxes_taxes\",\n",
    "            \"school\",\n",
    "            \"total_crime\",\n",
    "            \"violent_crime\",\n",
    "            \"property_crime\",\n",
    "            \"foreclosures\",\n",
    "        )\n",
    "\n",
    "        # Ghi các tên cột vào file output, mỗi cột ngăn cách bởi \"\\t\".\n",
    "        fOut.write(f\"{tab.join(headers)}\\n\")\n",
    "\n",
    "        # Duyệt từng line trong file Input (json).\n",
    "        for line in fIn:\n",
    "            row = json.loads(line)\n",
    "\n",
    "            # Lấy địa chỉ\n",
    "            address = row.get(\"address\")\n",
    "            address_street = address.get(\"street\")\n",
    "            address_locality = address.get(\"locality\")\n",
    "            address_region = address.get(\"region\")\n",
    "            address_code = address.get(\"code\")\n",
    "\n",
    "            # Lấy ngày bán thành công.\n",
    "            date_sold = row.get(\"date_sold\")\n",
    "\n",
    "            # Lấy giá cho thuê mỗi tháng (trước khi được bán).\n",
    "            mortgage = row.get(\"mortgage\")\n",
    "            if mortgage is not None:\n",
    "                mortgage = float(mortgage.replace(\"$\",\"\").replace(\",\",\"\").replace(\"/mo\",\"\").replace(\"Est. Refinance: \", \"\"))\n",
    "\n",
    "            # Lấy phần info\n",
    "            info = row.get(\"info\")\n",
    "\n",
    "            # Type.\n",
    "            info_type = info.get(\"type\")\n",
    "\n",
    "            # Bedrooms.\n",
    "            info_bedrooms = info.get(\"bedrooms\")\n",
    "            if info_bedrooms == \"Contact Agent\":\n",
    "                info_bedrooms = None\n",
    "            else:\n",
    "                info_bedrooms = float(info_bedrooms)\n",
    "\n",
    "            # Bathrooms.\n",
    "            info_bathrooms = info.get(\"bathrooms\")\n",
    "            if info_bathrooms == \"Contact Agent\":\n",
    "                info_bathrooms = None\n",
    "            else:\n",
    "                info_bathrooms = float(info_bathrooms)\n",
    "\n",
    "            # Size.\n",
    "            info_size = info.get(\"size\")\n",
    "            if info_size == \"Contact Agent\":\n",
    "                info_size = None\n",
    "            else:\n",
    "                info_size = float(info_size.replace(\",\", \"\").replace(\" sqft\", \"\"))\n",
    "\n",
    "            # Lot size.\n",
    "            info_lot_size = info.get(\"lot_size\")\n",
    "            if info_lot_size == \"Contact Agent\":\n",
    "                info_lot_size = None\n",
    "            else:\n",
    "                info_lot_size = float(info_lot_size.replace(\",\", \"\").replace(\" sqft\", \"\").replace(\" acres\", \"\"))\n",
    "\n",
    "            # Year build.\n",
    "            info_year_built = info.get(\"year_built\")\n",
    "            if info_year_built  == \"Contact Agent\":\n",
    "                info_year_built = None\n",
    "            else:\n",
    "                info_year_built = int(info_year_built)\n",
    "\n",
    "            # Est value.\n",
    "            info_est_value = info.get(\"est._value\")\n",
    "            if info_est_value is not None:\n",
    "                info_est_value = float(info_est_value.replace(\"$\", \"\").replace(\",\",\"\"))\n",
    "\n",
    "            # Sold price.\n",
    "            info_sold_price = info.get(\"sold_price\")\n",
    "            if info_sold_price is not None:\n",
    "                if info_sold_price != \"N/A\":\n",
    "                    info_sold_price = float(info_sold_price.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "\n",
    "            # ID.\n",
    "            info_property_id = info.get(\"property_id\")\n",
    "\n",
    "            # County.\n",
    "            info_county = info.get(\"county\")\n",
    "\n",
    "            # Parcel_number.\n",
    "            info_parcel_number = info.get(\"parcel_number\")\n",
    "\n",
    "            # Lấy phần Taxes.\n",
    "            taxes = row.get(\"property_taxes\")\n",
    "            taxes_land = None\n",
    "            taxes_improvements = None\n",
    "            taxes_total = None\n",
    "            taxes_taxes = None\n",
    "            if taxes is not None:\n",
    "                taxes_land = float(taxes.get(\"land\").replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "                taxes_improvements = float(taxes.get(\"improvements\").replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "                taxes_total = float(taxes.get(\"total\").replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "                taxes_taxes = taxes.get(\"taxes\").replace(\"$\", \"\").replace(\",\", \"\")\n",
    "\n",
    "            # Lấy số lượng scholl gần đó.\n",
    "            school = int(row.get(\"school\"))\n",
    "\n",
    "            # Lấy tình hình tội phạm.\n",
    "            crime = row.get(\"local_crime_index\")\n",
    "            if crime is not None:\n",
    "                total_crime = crime.get(\"total_crime\")\n",
    "                if total_crime is not None:\n",
    "                    total_crime = int(total_crime)\n",
    "                violent_crime = crime.get(\"violent_crime\")\n",
    "                if violent_crime is not None:\n",
    "                    violent_crime = int(violent_crime)\n",
    "                property_crime = crime.get(\"property_crime\")\n",
    "                if property_crime is not None:\n",
    "                    property_crime = int(property_crime)\n",
    "\n",
    "            # Lấy số lượng foreclosures gần đó.\n",
    "            foreclosures = int(row.get(\"foreclosures\"))\n",
    "\n",
    "            # Row này là tổng hợp các thông tin lấy được ở trên.\n",
    "            row = (\n",
    "                xstr(address_street),\n",
    "                xstr(address_locality),\n",
    "                xstr(address_region),\n",
    "                xstr(address_code),\n",
    "                xstr(date_sold),\n",
    "                xstr(mortgage),\n",
    "                xstr(info_type),\n",
    "                xstr(info_bedrooms),\n",
    "                xstr(info_bathrooms),\n",
    "                xstr(info_size),\n",
    "                xstr(info_lot_size),\n",
    "                xstr(info_year_built),\n",
    "                xstr(info_est_value),\n",
    "                xstr(info_sold_price),\n",
    "                xstr(info_property_id),\n",
    "                xstr(info_county),\n",
    "                xstr(info_parcel_number),\n",
    "                xstr(taxes_land),\n",
    "                xstr(taxes_improvements),\n",
    "                xstr(taxes_total),\n",
    "                xstr(taxes_taxes),\n",
    "                xstr(school),\n",
    "                xstr(total_crime),\n",
    "                xstr(violent_crime),\n",
    "                xstr(property_crime),\n",
    "                xstr(foreclosures),\n",
    "            )\n",
    "\n",
    "            # Ghi xuống file output\n",
    "            fOut.write(f\"{tab.join(row)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Sở dĩ nhóm không thêm phần `description` vào dữ liệu là bởi vì khi quan sát phần mã `html` của `description` thì phát hiện ra nó được viết theo một `format` nhất định, các thông tin số liệu của nó được lấy từ các bảng số liệu trong cùng một trang web (tức là các phần thông tin nhà, thuế,.. mà mình đã parse ở trên). Nếu số liệu nào có thì sẽ được lấy ra và tạo một câu mô tả theo `format` cho trước, còn số liệu nào không có thì hiển nhiên không xuất hiện câu đó. Như vậy, có thể kết luận là phần `description` lúc này sẽ không giúp ích gì cho chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"data/full-orange-county.json\"\n",
    "outputFile = \"data/orange-county.csv\"\n",
    "preprocessFile(inputFile, outputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Lựa chọn dữ liệu của năm 2019 và có \"correct ouput\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Xóa dữ liệu trùng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dữ liệu ban đầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu lên\n",
    "file_csv = \"data/Orange-County/orange-county.csv\"\n",
    "data_df =  pd.read_csv(file_csv, sep='\\t')\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu ban đầu có 21268 dòng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dữ liệu sau khi xóa trùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa các phần dữ liệu bị trùng\n",
    "unique_data_df = data_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem phần dữ liệu khi đã xóa trùng\n",
    "unique_data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu sau khi xóa trùng còn lại 18893 dòng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi dữ liệu xuống file csv\n",
    "unique_data_df.to_csv(\"data/Orange-County/delete-duplicate-orange.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Lấy dữ liệu của năm 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu lên\n",
    "df = pd.read_csv(\"data/Orange-County/delete-duplicate-orange.csv\", sep='\\t')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm cột năm bán vào dữ liệu\n",
    "df = df.assign(year_sold=df.date_sold.str[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem dữ liệu này thu thập của các năm nào\n",
    "df.year_sold.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chỉ lấy phần dữ liệu của năm 2019\n",
    "df = df[df.year_sold == \"2019\"]\n",
    "df.year_sold = df.year_sold.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi dữ liệu xuống file csv\n",
    "df.to_csv(\"data/Orange-County/delete-duplicate-orange-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Lấy dữ liệu của năm 2019 có \"correct output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "data_df = pd.read_csv(\"data/Orange-County/delete-duplicate-orange-2019.csv\", sep='\\t')\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu có 16011 căn nhà được bán trong 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta chỉ lấy dữ liệu có `info_sold_price` khác `null`. Như đã nói ở phần cuối của `1.1. Parse HTML` thì không thể tìm kiếm các giá trị chính xác từ phần `decription` để có thể lắp đầy giá trị `null`, mà nếu có tìm cũng chỉ toàn ra giá trị trung bình của các căn nhà được bán lân cận chứ không phải giá trị chính xác của nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_df[pd.notna(data_df[\"info_sold_price\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu còn lại là 15755.\n",
    "\n",
    "&#9889; Sau khi xóa các dòng có sold_price là `null`. Xem lại cột `info_est_value` thấy toàn `null`, cột này ý nghĩa là giá trị định giá của căn nhà trên các bản rao bán (chưa chốt giá). Nên xóa đi cột này là hoàn toàn hợp lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"info_est_value\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cần kiểm tra xem ứng với `15755` dòng dữ liệu thì phải có đúng `15755` `info_property_id` hay không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.info_property_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ổn vì có đúng `15755` `info_property_id` như mong muốn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, ta kiểm tra liệu ứng với mỗi `address_street` liệu chỉ có duy nhất một căn nhà được bán thành công hay không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_street_count = df.address_street.value_counts()\n",
    "address_street_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy có `38` `address_street` có số lượng nhà bán thành công trong năm 2019 lơn hơn 1, trong đó lại có `1600 S Disneyland Dr` có số lần xuất hiện lên đến con sô `16`, điều này hơi kỳ lạ. Vì vậy, ta cần quan sát thêm về các `addresss_street` kiểu này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy tên các addresss_street có số lượng nhà được bán trong năm 2019 nhiều hơn 1\n",
    "duplicate_addresss_street = address_street_count[address_street_count > 1].index\n",
    "duplicate_addresss_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicate_addresss_street)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thử tất cả các dòng có `address_street` là `1600 S Disneyland Dr` (hay `duplicate_addresss_street[0]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[df.address_street == duplicate_addresss_street[0]]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.info_sold_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với những dòng có cùng `address_street` mà lại khác `date_sold` và `info_sold_price` thì nên bỏ là hợp lý và khó có thể lấy được chính xác giá trị `sold_price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp tục, xem thử tất cả các dòng có `address_street` là `200 W Midway Dr ` (hay `duplicate_addresss_street[1]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[df.address_street == duplicate_addresss_street[1]]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.info_sold_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mặc dù có cùng `address_street`, cùng `date_sold` và cùng `info_sold_price` nhưng lại có các giá trị `taxes` thay đổi một cách kỳ lại + với các thông tin chính (`info_bedrooms`, `info_bathroooms`,...) bị thiếu. Phần các thông tin chính này có thể giải quyết bằng `fill miss value` (`mean`, `median`, `most`,...) nhưng phần `taxes` thì nhóm không biết xác định như thế nào cho hợp lý và gần chính xác nhất. Nên quyết định bỏ luôn các dòng dạng này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(address_street_count[address_street_count > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có `106` dòng dữ liệu bị như thế, so với `15755` dòng dữ liệu hiện có thì chúng chưa chiếm đến `1%` nên nhóm quyết định bỏ đi là hợp lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.address_street.isin(duplicate_addresss_street)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi dữ liệu xuống file csv.\n",
    "df.to_csv(\"data/Orange-County/data-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tách dữ liệu thành 2 tập train và test theo tỉ lệ 80% 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu lên\n",
    "data_df = pd.read_csv(\"data/Orange-County/data-2019.csv\", sep='\\t')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đổi tên\n",
    "data_df = data_df.rename(columns={\"info_sold_price\": \"sold_price\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách dữ liệu theo tỉ lệ 80% và 20%\n",
    "train, test = train_test_split(data_df, test_size=0.2, random_state=0)\n",
    "train.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Nhóm đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của thầy ra giống với của nhóm. Kết quả của câu lệnh `train.head().index` của nhóm ra 5 giá trị là: [2746, 8859, 11288, 2153, 12119]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi tập train\n",
    "train.to_csv(\"data/Orange-County/train-data-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghi tập test\n",
    "test.to_csv(\"data/Orange-County/test-data-2019.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_street</th>\n",
       "      <th>address_locality</th>\n",
       "      <th>address_region</th>\n",
       "      <th>address_code</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>info_type</th>\n",
       "      <th>info_bedrooms</th>\n",
       "      <th>info_bathrooms</th>\n",
       "      <th>info_size</th>\n",
       "      <th>...</th>\n",
       "      <th>taxes_land</th>\n",
       "      <th>taxes_improvements</th>\n",
       "      <th>taxes_total</th>\n",
       "      <th>taxes_taxes</th>\n",
       "      <th>school</th>\n",
       "      <th>total_crime</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>foreclosures</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13242 Amarillo Dr</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>CA</td>\n",
       "      <td>92683</td>\n",
       "      <td>10/24/2019</td>\n",
       "      <td>3157.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>...</td>\n",
       "      <td>508260.0</td>\n",
       "      <td>54780.0</td>\n",
       "      <td>563040.0</td>\n",
       "      <td>6969 (1.23 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>716 S Palomino Ln</td>\n",
       "      <td>Anaheim</td>\n",
       "      <td>CA</td>\n",
       "      <td>92807</td>\n",
       "      <td>08/16/2019</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>371674.0</td>\n",
       "      <td>148526.0</td>\n",
       "      <td>520200.0</td>\n",
       "      <td>5527 (1.06 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19702 Lancewood Plz</td>\n",
       "      <td>Yorba Linda</td>\n",
       "      <td>CA</td>\n",
       "      <td>92886</td>\n",
       "      <td>07/23/2019</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29459.0</td>\n",
       "      <td>43373.0</td>\n",
       "      <td>72832.0</td>\n",
       "      <td>1240 (1.70 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25885 Trabuco Rd Apt 59</td>\n",
       "      <td>Lake Forest</td>\n",
       "      <td>CA</td>\n",
       "      <td>92630</td>\n",
       "      <td>10/30/2019</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112879.0</td>\n",
       "      <td>93656.0</td>\n",
       "      <td>206535.0</td>\n",
       "      <td>2096 (1.01 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6742 Gate Hill Cir</td>\n",
       "      <td>Huntington Beach</td>\n",
       "      <td>CA</td>\n",
       "      <td>92648</td>\n",
       "      <td>07/15/2019</td>\n",
       "      <td>5860.0</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159764.0</td>\n",
       "      <td>148957.0</td>\n",
       "      <td>308721.0</td>\n",
       "      <td>3706 (1.20 %)</td>\n",
       "      <td>3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            address_street  address_locality address_region  address_code  \\\n",
       "0        13242 Amarillo Dr       Westminster             CA         92683   \n",
       "1        716 S Palomino Ln           Anaheim             CA         92807   \n",
       "2      19702 Lancewood Plz       Yorba Linda             CA         92886   \n",
       "3  25885 Trabuco Rd Apt 59       Lake Forest             CA         92630   \n",
       "4       6742 Gate Hill Cir  Huntington Beach             CA         92648   \n",
       "\n",
       "    date_sold  mortgage                info_type  info_bedrooms  \\\n",
       "0  10/24/2019    3157.0  Single Family Residence            3.0   \n",
       "1  08/16/2019    2748.0  Single Family Residence            3.0   \n",
       "2  07/23/2019    2966.0  Single Family Residence            4.0   \n",
       "3  10/30/2019    1726.0              Condominium            2.0   \n",
       "4  07/15/2019    5860.0  Single Family Residence            4.0   \n",
       "\n",
       "   info_bathrooms  info_size  ...  taxes_land  taxes_improvements  \\\n",
       "0             1.0     1090.0  ...    508260.0             54780.0   \n",
       "1             3.0     1582.0  ...    371674.0            148526.0   \n",
       "2             2.0     1440.0  ...     29459.0             43373.0   \n",
       "3             2.0     1190.0  ...    112879.0             93656.0   \n",
       "4             3.0     2193.0  ...    159764.0            148957.0   \n",
       "\n",
       "   taxes_total    taxes_taxes school  total_crime  violent_crime  \\\n",
       "0     563040.0  6969 (1.23 %)      3         97.0           79.0   \n",
       "1     520200.0  5527 (1.06 %)      3         88.0           71.0   \n",
       "2      72832.0  1240 (1.70 %)      3         22.0           12.0   \n",
       "3     206535.0  2096 (1.01 %)      3         29.0           23.0   \n",
       "4     308721.0  3706 (1.20 %)      3         57.0           47.0   \n",
       "\n",
       "   property_crime  foreclosures year_sold  \n",
       "0           140.0             4      2019  \n",
       "1           127.0             4      2019  \n",
       "2            44.0             4      2019  \n",
       "3            42.0             4      2019  \n",
       "4            82.0             4      2019  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/Orange-County/train-data-2019.csv\", sep='\\t')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12519 entries, 0 to 12518\n",
      "Data columns (total 26 columns):\n",
      "address_street        12485 non-null object\n",
      "address_locality      12519 non-null object\n",
      "address_region        12519 non-null object\n",
      "address_code          12519 non-null int64\n",
      "date_sold             12519 non-null object\n",
      "mortgage              12519 non-null float64\n",
      "info_type             12519 non-null object\n",
      "info_bedrooms         11363 non-null float64\n",
      "info_bathrooms        11371 non-null float64\n",
      "info_size             11946 non-null float64\n",
      "info_lot_size         8484 non-null float64\n",
      "info_year_built       11571 non-null float64\n",
      "sold_price            12519 non-null float64\n",
      "info_property_id      12519 non-null int64\n",
      "info_county           12519 non-null object\n",
      "info_parcel_number    12519 non-null int64\n",
      "taxes_land            12321 non-null float64\n",
      "taxes_improvements    12321 non-null float64\n",
      "taxes_total           12321 non-null float64\n",
      "taxes_taxes           12321 non-null object\n",
      "school                12519 non-null int64\n",
      "total_crime           12156 non-null float64\n",
      "violent_crime         12156 non-null float64\n",
      "property_crime        12156 non-null float64\n",
      "foreclosures          12519 non-null int64\n",
      "year_sold             12519 non-null int64\n",
      "dtypes: float64(13), int64(6), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tập train có `12519` dòng dữ liệu và `26` cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_street</th>\n",
       "      <th>address_locality</th>\n",
       "      <th>address_region</th>\n",
       "      <th>address_code</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>info_type</th>\n",
       "      <th>info_bedrooms</th>\n",
       "      <th>info_bathrooms</th>\n",
       "      <th>info_size</th>\n",
       "      <th>...</th>\n",
       "      <th>taxes_land</th>\n",
       "      <th>taxes_improvements</th>\n",
       "      <th>taxes_total</th>\n",
       "      <th>taxes_taxes</th>\n",
       "      <th>school</th>\n",
       "      <th>total_crime</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>foreclosures</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12485</td>\n",
       "      <td>12519</td>\n",
       "      <td>12519</td>\n",
       "      <td>12519.000000</td>\n",
       "      <td>12519</td>\n",
       "      <td>1.251900e+04</td>\n",
       "      <td>12519</td>\n",
       "      <td>11363.000000</td>\n",
       "      <td>11371.000000</td>\n",
       "      <td>11946.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232100e+04</td>\n",
       "      <td>1.232100e+04</td>\n",
       "      <td>1.232100e+04</td>\n",
       "      <td>12321</td>\n",
       "      <td>12519.000000</td>\n",
       "      <td>12156.000000</td>\n",
       "      <td>12156.000000</td>\n",
       "      <td>12156.000000</td>\n",
       "      <td>12519.000000</td>\n",
       "      <td>12519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12485</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2127 W Dogwood Ave</td>\n",
       "      <td>Irvine</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/28/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10555 (1.12 %)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>12517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92552.015816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.928697e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.124263</td>\n",
       "      <td>2.602102</td>\n",
       "      <td>2426.583208</td>\n",
       "      <td>...</td>\n",
       "      <td>5.009780e+05</td>\n",
       "      <td>2.826592e+05</td>\n",
       "      <td>7.836531e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.884016</td>\n",
       "      <td>54.516946</td>\n",
       "      <td>42.570171</td>\n",
       "      <td>82.203274</td>\n",
       "      <td>3.853822</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>564.557227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.526277e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008088</td>\n",
       "      <td>0.991297</td>\n",
       "      <td>7797.643516</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434805e+06</td>\n",
       "      <td>1.751883e+06</td>\n",
       "      <td>2.832966e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578382</td>\n",
       "      <td>29.778698</td>\n",
       "      <td>28.960716</td>\n",
       "      <td>37.985382</td>\n",
       "      <td>0.750273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90620.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.410000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92630.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.548000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1264.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.504430e+05</td>\n",
       "      <td>7.841300e+04</td>\n",
       "      <td>2.769060e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92677.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.339000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1671.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111640e+05</td>\n",
       "      <td>1.312930e+05</td>\n",
       "      <td>4.712400e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92804.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.610000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2377.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.119080e+05</td>\n",
       "      <td>2.319820e+05</td>\n",
       "      <td>7.320000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92887.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.078417e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>450854.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.929106e+07</td>\n",
       "      <td>9.338348e+07</td>\n",
       "      <td>1.447999e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            address_street address_locality address_region  address_code  \\\n",
       "count                12485            12519          12519  12519.000000   \n",
       "unique               12485               52              2           NaN   \n",
       "top     2127 W Dogwood Ave           Irvine             CA           NaN   \n",
       "freq                     1             1107          12517           NaN   \n",
       "mean                   NaN              NaN            NaN  92552.015816   \n",
       "std                    NaN              NaN            NaN    564.557227   \n",
       "min                    NaN              NaN            NaN  90620.000000   \n",
       "25%                    NaN              NaN            NaN  92630.000000   \n",
       "50%                    NaN              NaN            NaN  92677.000000   \n",
       "75%                    NaN              NaN            NaN  92804.000000   \n",
       "max                    NaN              NaN            NaN  92887.000000   \n",
       "\n",
       "         date_sold      mortgage                info_type  info_bedrooms  \\\n",
       "count        12519  1.251900e+04                    12519   11363.000000   \n",
       "unique         155           NaN                       14            NaN   \n",
       "top     06/28/2019           NaN  Single Family Residence            NaN   \n",
       "freq           232           NaN                     8162            NaN   \n",
       "mean           NaN  8.928697e+03                      NaN       3.124263   \n",
       "std            NaN  7.526277e+04                      NaN       1.008088   \n",
       "min            NaN  2.000000e+00                      NaN       1.000000   \n",
       "25%            NaN  2.548000e+03                      NaN       2.000000   \n",
       "50%            NaN  3.339000e+03                      NaN       3.000000   \n",
       "75%            NaN  4.610000e+03                      NaN       4.000000   \n",
       "max            NaN  2.078417e+06                      NaN       8.000000   \n",
       "\n",
       "        info_bathrooms      info_size  ...    taxes_land  taxes_improvements  \\\n",
       "count     11371.000000   11946.000000  ...  1.232100e+04        1.232100e+04   \n",
       "unique             NaN            NaN  ...           NaN                 NaN   \n",
       "top                NaN            NaN  ...           NaN                 NaN   \n",
       "freq               NaN            NaN  ...           NaN                 NaN   \n",
       "mean          2.602102    2426.583208  ...  5.009780e+05        2.826592e+05   \n",
       "std           0.991297    7797.643516  ...  1.434805e+06        1.751883e+06   \n",
       "min           1.000000     301.000000  ...  4.410000e+02        0.000000e+00   \n",
       "25%           2.000000    1264.000000  ...  1.504430e+05        7.841300e+04   \n",
       "50%           3.000000    1671.000000  ...  3.111640e+05        1.312930e+05   \n",
       "75%           3.000000    2377.750000  ...  5.119080e+05        2.319820e+05   \n",
       "max          11.000000  450854.000000  ...  6.929106e+07        9.338348e+07   \n",
       "\n",
       "         taxes_total     taxes_taxes        school   total_crime  \\\n",
       "count   1.232100e+04           12321  12519.000000  12156.000000   \n",
       "unique           NaN           11959           NaN           NaN   \n",
       "top              NaN  10555 (1.12 %)           NaN           NaN   \n",
       "freq             NaN              19           NaN           NaN   \n",
       "mean    7.836531e+05             NaN      2.884016     54.516946   \n",
       "std     2.832966e+06             NaN      0.578382     29.778698   \n",
       "min     0.000000e+00             NaN      0.000000     13.000000   \n",
       "25%     2.769060e+05             NaN      3.000000     29.000000   \n",
       "50%     4.712400e+05             NaN      3.000000     55.000000   \n",
       "75%     7.320000e+05             NaN      3.000000     71.000000   \n",
       "max     1.447999e+08             NaN      3.000000    128.000000   \n",
       "\n",
       "        violent_crime  property_crime  foreclosures year_sold  \n",
       "count    12156.000000    12156.000000  12519.000000   12519.0  \n",
       "unique            NaN             NaN           NaN       NaN  \n",
       "top               NaN             NaN           NaN       NaN  \n",
       "freq              NaN             NaN           NaN       NaN  \n",
       "mean        42.570171       82.203274      3.853822    2019.0  \n",
       "std         28.960716       37.985382      0.750273       0.0  \n",
       "min          1.000000       23.000000      0.000000    2019.0  \n",
       "25%         22.000000       48.000000      4.000000    2019.0  \n",
       "50%         39.000000       82.000000      4.000000    2019.0  \n",
       "75%         54.000000      122.000000      4.000000    2019.0  \n",
       "max        128.000000      162.000000      4.000000    2019.0  \n",
       "\n",
       "[11 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Tách tập dữ liệu thành 2 phần train (70%) và validation (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách X và y\n",
    "y_sr = data_df[\"sold_price\"] # sr là viết tắt của series\n",
    "X_df = data_df.drop(\"sold_price\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([10747, 12214, 5916, 489, 12257], dtype='int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tách tập train và tập validation theo tỉ lệ 70%:30%\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(X_df, y_sr, test_size=0.3, random_state=0)\n",
    "train_X_df.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Nhóm đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của thầy ra giống với của nhóm. Kết quả của câu lệnh `train_X_df.head().index` của nhóm ra 5 giá trị là: [10747, 12214, 5916, 489, 12257]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8763 entries, 10747 to 2732\n",
      "Data columns (total 25 columns):\n",
      "address_street        8736 non-null object\n",
      "address_locality      8763 non-null object\n",
      "address_region        8763 non-null object\n",
      "address_code          8763 non-null int64\n",
      "date_sold             8763 non-null object\n",
      "mortgage              8763 non-null float64\n",
      "info_type             8763 non-null object\n",
      "info_bedrooms         7951 non-null float64\n",
      "info_bathrooms        7956 non-null float64\n",
      "info_size             8361 non-null float64\n",
      "info_lot_size         5931 non-null float64\n",
      "info_year_built       8099 non-null float64\n",
      "info_property_id      8763 non-null int64\n",
      "info_county           8763 non-null object\n",
      "info_parcel_number    8763 non-null int64\n",
      "taxes_land            8632 non-null float64\n",
      "taxes_improvements    8632 non-null float64\n",
      "taxes_total           8632 non-null float64\n",
      "taxes_taxes           8632 non-null object\n",
      "school                8763 non-null int64\n",
      "total_crime           8498 non-null float64\n",
      "violent_crime         8498 non-null float64\n",
      "property_crime        8498 non-null float64\n",
      "foreclosures          8763 non-null int64\n",
      "year_sold             8763 non-null int64\n",
      "dtypes: float64(12), int64(6), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_X_df` có `8763` dòng dữ liệu và `25` cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3756 entries, 1540 to 4911\n",
      "Data columns (total 25 columns):\n",
      "address_street        3749 non-null object\n",
      "address_locality      3756 non-null object\n",
      "address_region        3756 non-null object\n",
      "address_code          3756 non-null int64\n",
      "date_sold             3756 non-null object\n",
      "mortgage              3756 non-null float64\n",
      "info_type             3756 non-null object\n",
      "info_bedrooms         3412 non-null float64\n",
      "info_bathrooms        3415 non-null float64\n",
      "info_size             3585 non-null float64\n",
      "info_lot_size         2553 non-null float64\n",
      "info_year_built       3472 non-null float64\n",
      "info_property_id      3756 non-null int64\n",
      "info_county           3756 non-null object\n",
      "info_parcel_number    3756 non-null int64\n",
      "taxes_land            3689 non-null float64\n",
      "taxes_improvements    3689 non-null float64\n",
      "taxes_total           3689 non-null float64\n",
      "taxes_taxes           3689 non-null object\n",
      "school                3756 non-null int64\n",
      "total_crime           3658 non-null float64\n",
      "violent_crime         3658 non-null float64\n",
      "property_crime        3658 non-null float64\n",
      "foreclosures          3756 non-null int64\n",
      "year_sold             3756 non-null int64\n",
      "dtypes: float64(12), int64(6), object(7)\n",
      "memory usage: 762.9+ KB\n"
     ]
    }
   ],
   "source": [
    "val_X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`val_X_df` có `3756` dòng dữ liệu và `25` cột."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Quan sát và lựa chọn dữ liệu bằng kiến thức cá nhân trên tập train (`train_X_df` và `train_y_sr`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Quan sát cột `address_street`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55105280/how-to-extract-apartment-from-address-in-pandas\n",
    "pat = r'^(?P<number>\\d+)?(?P<direction>.\\w(?= ))?(?P<street>.+(?=\\bapt|\\bunit)|.+(?=#)|.+)(?P<apt_unit>(?:\\bapt|\\bunit|#|).+)?'\n",
    "lower_address_street = train_X_df.address_street.str.lower()\n",
    "tmp = lower_address_street.str.extract(pat)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"street\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tmp[\"street\"].value_counts() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp[\"street\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo kết quả tìm kiếm trên internet (https://cartographic.info/usa/street/show.php?p=california&t=Orange%20County) thì có `280` tên đường lớn tại `Orange County`. Vậy trong danh sách mà nhóm parse được có đến `6051` tên đường khác nhau, chắc bao gồm những con đường nhỏ. Việc dùng `street` cho huấn luyện mô hình sẽ không hiệu quả, vì khi đưa vào mô hình bằng phương pháp one-hot chắc chắn sẽ tạo ra số chiều rất lớn và với một số địa chỉ xuất hiện rất ít dễ dẫn đén overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp[pd.notna(tmp[\"apt_unit\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhóm sẽ xóa cột `address_street` và thêm cột `apt_unit` được rút trích ở trên vào dữ liệu ở bước tiền xử lý dữ liệu, cột này chỉ có 2 giá trị (`True`/`False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Quan sát các cột `address_locality`, `address_region` và `address_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9889; Theo tìm hiểu của nhóm, `address_code` là tổng hợp từ `address_locality` và `address_region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_code = train_X_df.address_code.unique()\n",
    "len(unique_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in unique_code:\n",
    "    tmp_df = train_X_df[train_X_df.address_code == code]\n",
    "    print(\"Code: \" + str(code))\n",
    "    print(\"\\n + Locality: \" + str(tmp_df.address_locality.unique()))\n",
    "    print(\"\\n + Region: \" + str(tmp_df.address_region.unique()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo nhóm tìm hiểu thì mã `code` (`address_code`) kia là mã bưu điện, mã này có thể dùng cho nhiều `locality` ở gần nhau, do đó ta kết quả như ở trên là hoàn toàn bình thường. Giờ nhóm quyết định bỏ 2 cột `address_locality` và `addres_region`, chỉ giữ lại cột `address_code` là đủ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `address_code` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_code = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.address_code)])\n",
    "print(\"The number of missing values (column 'address_code'): \" + str(num_miss_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `address_code` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Quan sát cột `date_sold`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xem thử cột `date_sold` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values (column 'date_sold'): 0\n"
     ]
    }
   ],
   "source": [
    "num_miss_date_sold = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.date_sold)])\n",
    "print(\"The number of missing values (column 'date_sold'): \" + str(num_miss_date_sold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `date_sold` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rút trích thông tin từ cột `date_sold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['09/11/2019', '08/23/2019', '07/29/2019', '08/22/2019',\n",
       "       '07/25/2019', '06/13/2019', '11/20/2019', '06/20/2019',\n",
       "       '08/06/2019', '06/10/2019', '06/17/2019', '07/12/2019',\n",
       "       '08/01/2019', '11/07/2019', '07/03/2019', '09/23/2019',\n",
       "       '10/08/2019', '08/19/2019', '08/09/2019', '06/27/2019',\n",
       "       '06/28/2019', '11/19/2019', '10/24/2019', '06/11/2019',\n",
       "       '09/12/2019', '08/20/2019', '10/17/2019', '09/25/2019',\n",
       "       '11/01/2019', '11/14/2019', '08/16/2019', '09/17/2019',\n",
       "       '08/15/2019', '07/26/2019', '07/05/2019', '07/08/2019',\n",
       "       '09/24/2019', '07/18/2019', '09/13/2019', '08/30/2019',\n",
       "       '09/20/2019', '08/26/2019', '10/11/2019', '02/04/2019',\n",
       "       '07/31/2019', '06/18/2019', '06/24/2019', '11/06/2019',\n",
       "       '10/09/2019', '09/26/2019', '06/14/2019', '10/16/2019',\n",
       "       '09/09/2019', '10/07/2019', '07/19/2019', '07/09/2019',\n",
       "       '11/15/2019', '07/15/2019', '06/26/2019', '08/14/2019',\n",
       "       '09/30/2019', '09/06/2019', '10/03/2019', '10/25/2019',\n",
       "       '08/08/2019', '09/27/2019', '07/30/2019', '07/24/2019',\n",
       "       '07/11/2019', '09/05/2019', '08/28/2019', '11/05/2019',\n",
       "       '06/25/2019', '07/02/2019', '11/08/2019', '10/28/2019',\n",
       "       '10/15/2019', '11/12/2019', '08/05/2019', '10/30/2019',\n",
       "       '10/29/2019', '07/17/2019', '11/13/2019', '03/05/2019',\n",
       "       '10/10/2019', '08/07/2019', '07/22/2019', '09/04/2019',\n",
       "       '07/10/2019', '10/31/2019', '08/29/2019', '11/18/2019',\n",
       "       '06/19/2019', '04/09/2019', '08/02/2019', '10/01/2019',\n",
       "       '08/12/2019', '07/16/2019', '06/21/2019', '10/22/2019',\n",
       "       '08/13/2019', '10/04/2019', '07/01/2019', '09/16/2019',\n",
       "       '09/10/2019', '10/21/2019', '07/23/2019', '09/19/2019',\n",
       "       '11/21/2019', '11/04/2019', '10/23/2019', '10/18/2019',\n",
       "       '06/12/2019', '08/27/2019', '08/21/2019', '10/02/2019',\n",
       "       '02/22/2019', '09/18/2019', '02/11/2019', '04/16/2019',\n",
       "       '09/03/2019', '01/31/2019', '04/04/2019', '05/28/2019',\n",
       "       '11/22/2019', '05/30/2019', '04/03/2019', '04/26/2019',\n",
       "       '05/21/2019', '05/22/2019', '06/05/2019', '03/22/2019',\n",
       "       '05/31/2019', '01/09/2019', '05/15/2019', '03/27/2019',\n",
       "       '03/28/2019', '04/30/2019', '01/04/2019', '04/22/2019',\n",
       "       '05/23/2019', '04/02/2019', '01/14/2019', '03/04/2019',\n",
       "       '03/29/2019', '03/19/2019', '05/16/2019', '05/20/2019',\n",
       "       '02/28/2019', '04/01/2019'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.date_sold.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `date_sold` được ghi dưới dạng `MM/DD/YYYY`. Giờ nhóm sẽ rút trích `Month` từ `date_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month = train_X_df.date_sold.str[:2].astype(int)\n",
    "sorted(month.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sở dĩ không có tháng `12` là do thời gian lấy dữ liệu của nhóm là đầu tháng `12` nên trang web chưa cập nhật. Về sau ở bước `Xây dựng pipline tiền xử lý dữ liệu`, nhóm sẽ tiến hành xóa cột `date_sold`, thêm cột `Month` và muốn thử để nguyên `11` tháng huấn luyện tốt hơn hay chia ra thành `4` mùa tốt hơn bằng cách đặt thêm cờ hiệu `month_to_seasion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10747    4\n",
       "12214    3\n",
       "5916     3\n",
       "489      3\n",
       "12257    3\n",
       "5010     3\n",
       "2271     4\n",
       "11574    3\n",
       "6780     3\n",
       "12148    3\n",
       "6472     3\n",
       "2560     3\n",
       "6759     3\n",
       "7948     3\n",
       "263      4\n",
       "7105     3\n",
       "5013     3\n",
       "658      4\n",
       "1462     4\n",
       "771      3\n",
       "6403     3\n",
       "2002     3\n",
       "9628     3\n",
       "4749     3\n",
       "8001     4\n",
       "3125     4\n",
       "10326    3\n",
       "12278    4\n",
       "8851     3\n",
       "3200     3\n",
       "        ..\n",
       "7599     4\n",
       "1871     4\n",
       "2046     4\n",
       "7877     4\n",
       "4851     3\n",
       "5072     3\n",
       "2163     4\n",
       "6036     4\n",
       "6921     3\n",
       "6216     4\n",
       "11085    4\n",
       "537      3\n",
       "9893     3\n",
       "2897     3\n",
       "7768     4\n",
       "2222     3\n",
       "10327    3\n",
       "2599     3\n",
       "705      3\n",
       "3468     4\n",
       "6744     3\n",
       "5874     3\n",
       "4373     4\n",
       "7891     3\n",
       "9225     4\n",
       "4859     4\n",
       "3264     4\n",
       "9845     4\n",
       "10799    4\n",
       "2732     3\n",
       "Name: date_sold, Length: 8763, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(month%12 + 3)//3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4. Quan sát cột `mortgage`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mortgage` là tiền cho thuê tính theo tháng của căn nhà khi chưa được bán, nó cũng gần gần để suy ra `sold_price` rồi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.mortgage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thử cột `mortgage` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_mortgage = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.mortgage)])\n",
    "print(\"The number of missing values (column 'mortgage'): \" + str(num_miss_mortgage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `mortgage` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5. Quan sát cột `info_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Quan sát các giá trị xuất hiện trong cột và số lượng tương ứng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có một số giá trị xuất hiện rất ít, nhóm thử dùng thêm tham số `num_top_type` để chọn ra các `info_type` xuất hiện nhiều lần; còn các giá trị nằm ngoài `num_top_type` nhóm sẽ cho là giá trị `Others`. (như `BT03-TienXuLy_ChongOverfit`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `address_type` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_type = train_X_df.shape[0] - len(train_X_df[pd.notna(train_X_df.info_type)])\n",
    "print(\"The number of missing values (column 'info_type'): \" + str(num_miss_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Cột `info_type` không có giá trị thiếu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5. Quan sát cột `info_bedrooms` và cột `info_bathrooms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xem thử cột `info_bedrooms` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_bedrooms = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_bedrooms)])\n",
    "print(\"The number of missing values (column 'info_bedrooms'): \" + str(num_miss_bedrooms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_bedrooms` có `812` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bedrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bedrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bedrooms.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do là `bedrooms` và các giá trị của nó là số nguyên, nên nhóm dùng `most` để lắp đầy các giá trị thiếu cho cột `info_bedrooms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `info_bathrooms` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_bathrooms = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_bathrooms)])\n",
    "print(\"The number of missing values (column 'info_bathrooms'): \" + str(num_miss_bathrooms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_bathrooms` có `807` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bathrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bathrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_bathrooms.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự nhóm cùng sẽ dùng `most` để lắp đầy các giá trị thiếu cho cột `info_bathrooms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6. Quan sát cột `info_size` và cột `info_lot_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xem thử cột `info_size` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_size= train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_size)])\n",
    "print(\"The number of missing values (column 'info_size'): \" + str(num_miss_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_size` có `402` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_size.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_X_df.info_size.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điền các giá trị thiếu bằng `mean`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Xem thử cột `info_lot_size` có bao nhiêu giá trị thiếu và chọn cách để lắp đầy các giá trị thiếu đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_lot_size= train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_lot_size)])\n",
    "print(\"The number of missing values (column 'info_size'): \" + str(num_miss_lot_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_size` có `2832` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_lot_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_lot_size.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_X_df.info_lot_size.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điền các giá trị thiếu bằng `mean`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.7. Quan sát cột `info_year_built`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thử cột `info_year_built` có bao nhiêu giá trị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_year_built = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.info_year_built)])\n",
    "print(\"The number of missing values (column 'info_size'): \" + str(num_miss_year_built))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `info_year_built` có `664` giá trị bị thiếu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_year_built.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.info_year_built.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_X_df.info_year_built.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.8. Quan sát các cột `info_property_id`, `info_county` và `info_parcel_number`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `info_property_id` là cột dạng số (numerical) - int64\n",
    "- `info_county` là cột dạng chuỗi có giá trị rời rạc không thứ tự (categorical)\n",
    "- `info_parcel_number` là cột dạng số (numerical) - int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bỏ đi các cột này, vì 2 cột `info_property_id` và `info_parcel_number` ứng với mỗi dòng dữ liệu là hoàn toàn khác nhau; còn cột `info_county` thì có giá trị là `Orange County` (do dữ liệu thu thập của Quận Cam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.9. Quan sát các cột `taxes_land`, `taxes_improvements`, `taxes_total` và `taxes_taxes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các cột này đều là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_taxes = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.taxes_land)])\n",
    "print(\"The number of missing values (column 'taxes'): \" + str(num_miss_taxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có `131` giá trị thiếu cho mỗi cột `taxes_land`, `taxes_improvements`, `taxes_total` và `taxes_taxes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search cùng `address_code` thì lắp đầy các giá trị thiếu bằng `mean` của các `taxes` trong cùng `address_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giữ nguyên các cột `taxes_land`, `taxes_improvements` và bỏ cột `taxes_total`. Giải thích thêm ý nghĩa của các cột này:\n",
    "- Cột `taxes_land` là tiền cải thuế cải tạo đất mà mình phải đóng cho chính phủ.\n",
    "- Cột `taxes_improvements` là tiền mà mình phải trả do sử dụng các tiện ích của chính phủ (cắt cỏ, tiền rác, củng cố hàng rào,...)\n",
    "- Cột `taxes_total` là tổng của 2 cột trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với cột `taxes_taxes` thì nhóm sẽ rút trích số tiền phải trả trong cột này ra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.taxes_taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.taxes_taxes.str.extract(r'(\\d+)', expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.10. Quan sát cột `school` và cột `foreclosures`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các cột này đều là cột dạng số (numerical) - int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai cột này không có giá trị thiếu, nên được giữ nguyên để huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.school.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.foreclosures.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.11. Quan sát cột `total_crime`, `violent_crime` và `property_crime`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các cột này đều là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích về ý nghĩa của các cột này. Giá trị mà các cột `total_crime`, `violent_crime` và `property_crime` biểu diễn được tính theo % so với tỉ lệ tội phạm quốc gia. Ví dụ `total_crime = 79` thì ở đây tổng số tội phạm là `79%` so với toàn nước (`100%`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_miss_crime = train_X_df.shape[0] - len(train_X_df[pd.notnull(train_X_df.total_crime)])\n",
    "print(\"The number of missing values (column 'taxes'): \" + str(num_miss_crime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có `265` giá trị thiếu cho mỗi cột `total_crime`, `violent_crime` và `property_crime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.total_crime.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search cùng `address_code` thì lắp đầy các giá trị thiếu bằng `median` của các `crime` trong cùng `address_code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.12. Quan sát `correct input` (`sold_price` của ` train_y_sr`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là cột dạng số (numerical) - float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sr.sort_values().sort_index().plot(style='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Thiết kế pipeline tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cột `address_street`: \n",
    "    - Ở đây có 4 thông tin được rút trích (xem  phần `4.2.1. Quan sát cột address_street` ở trên):\n",
    "         + `number`: số nhà, thông tin này không cần thiết cho việc huấn luyện.\n",
    "         + `direction`: hướng (đông, tây, nam, bắc) của đường, thông tin này không cần thiết cho việc huấn luyện.\n",
    "         + `street`: tên đường, theo kết quả parse thì thu được đến 6051 tên đường lớn/nhỏ khác nhau. Nếu đưa tên đường này vào huấn luyện thì có 3 vấn đề: thứ nhất là nếu dùng one-hot để chuyển sang dạng số thì sẽ làm tăng số chiều dữ liệu lên rất nhiều (thêm đến trên 6000 thuộc tính), thứ hai do có khoảng 1500 tên đường chỉ xuất hiện duy nhất một lần trong `train_X_df`, còn các tên đường khác thì cũng có tần số xuất hiện khá thấp (cao nhất chỉ có 16 lần) nên nếu thêm vào huấn luyện có thể dẫn đến overfitting, thứ 3 là nếu như ở tập `validation` hay tập `test` mà có tên đường không nằm trong tập `train` thì cũng khó khăn để giải quyết. Nên nhóm quyết định không lấy thông tin `street` để huấn luyện.\n",
    "         + `apt_unit`: cho biết căn nhà có thuộc chung cư nào hay không, thông tin này nhóm nghĩ là cần thiết cho việc huấn luyện vì nghĩ giá nhà riêng sẽ có phần nào khác với các căn nhà thuộc các khu chung cư. Vì vậy, sẽ thêm cột `is_apt` vào để huấn luyện, cột này chỉ có 2 giá trị `0`/`1` (nếu thuộc chung cư thì `1`, ngược lại thì `0`).\n",
    "    - Tóm lại, các việc cần làm:\n",
    "        + Rút trích ra cột `is_apt` (như mô tả ở trên) và thêm vào dữ liệu.\n",
    "        + Xóa cột `address_street`.\n",
    "        + Lắp đầy giá trị thiếu bằng KNN (n=5).\n",
    "        + Đây là dữ liệu số, để nguyên vậy vào huấn luyện.\n",
    "         \n",
    "2. Xóa 2 cột `address_locality` và cột `address_region`, giữ lại cột `address_code` (lý do xem ở phần `4.2.2. Quan sát các cột address_locality, address_region và address_code` ở trên). Ở tập `train_X_df` thì không thấy dữ liệu thiếu, nếu thiếu dùng KNN (n=5) để lấp đầy. Đưa vào tập train huấn luyện thì xem tại link (https://towardsdatascience.com/transforming-categorical-information-into-usable-measures-in-a-machine-learning-model-e2910bbb3fc7).\n",
    "3. Cột `date_sold`: rút trích `month` ra (xem ở phần `4.2.3. Quan sát cột date_sold`), xóa cột `date_sold` và `year_sol`, thêm vào cột `month_sold`. Ở tập `train_X_df` thì không thấy dữ liệu thiếu, nếu thiếu dùng KNN(n=5) để lấp đầy. Bỏ vào huấn luyện dùng one-hot, nhớ là thử để nguyên `11` tháng huấn luyện tốt hơn hay chia ra thành `4` mùa tốt hơn bằng cách đặt thêm cờ hiệu `month_to_season`.\n",
    "4. Cột `mortgage`: để nguyên. Ở tập `train_X_df` thì không thấy dữ liệu thiếu, nếu thiếu dùng KNN (n=5) để lấp đầy. Dạng số, cứ bỏ thẳng vào huấn luyện.\n",
    "5. Cột `info_type`: Có một số giá trị xuất hiện rất ít, nhóm thử dùng thêm tham số `num_top_types` để chọn ra các `info_type` xuất hiện nhiều lần; còn các giá trị nằm ngoài `num_top_types` nhóm sẽ cho là giá trị `Others`. (như `BT03-TienXuLy_ChongOverfit`). Ở tập `train_X_df` thì không thấy dữ liệu thiếu, nếu thiếu dùng KNN (n=5) để lấp đầy. Đưa vào huấn luyện thì dùng one-hot.\n",
    "6. Hai cột `info_bedrooms` và `info_bathrooms`: lắp đầy giá trị thiều bằng `most`. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "7. Hai cột `info_size` và `info_lot_size`: dùng KNN (n=5) để lắp đầy giá trị thiếu. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "8. Xóa 3 cột` info_property_id`, `info_county` và `info_parcel_number` (lý do xem ở phần `4.2.9. Quan sát các cột info_property_id, info_county và info_parcel_number`).\n",
    "9. Các cột `taxes_land`, `taxes_improvements`, `taxes_total` và `taxes_taxes`: đầu tiên rút trích `taxes` cho cột `taxes_taxes`, thay bằng dữ liệu tìm được (xem ở phần `4.2.10. Quan sát các cột taxes_land, taxes_improvements và taxes_taxes`), nhớ xóa cột `taxes_total`. Điền các giá trị thiếu bằng `mean`. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "10. Giữ nguyên cột `school` và cột `foreclosures`. Nếu có giá trị thiếu thì điền bằng `median`. Kiểu số, cứ bỏ thẳng vào huấn luyện.\n",
    "11. Các `total_crime`, `violent_crime` và `property_crime`: lắp đầy giá trị thiếu bằng `median`. Kiểu số, cứ bỏ thẳng vào huấn luyện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chuẩn hóa theo cách của thầy trong `BT03`.\n",
    "- Dùng mô hình `Linear Regression` để huấn luyện mô mình thử xem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class AddressProcessor dùng để xử lý các cột address_street, address_locality và address_region.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "class AddressProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Extract các thông tin (số nhà, hướng của đường, tên đường, tên chung cư) từ address_street.\n",
    "        pat = r'^(?P<number>\\d+)?(?P<direction>.\\w(?= ))?(?P<street>.+(?=\\bapt|\\bunit)|.+(?=#)|.+)(?P<apt_unit>(?:\\bapt|\\bunit|#|).+)?'\n",
    "        lower_address_street = X_df.address_street.str.lower()\n",
    "        street_parsed = lower_address_street.str.extract(pat)\n",
    "        \n",
    "        # Xóa các cột dùng nữa.\n",
    "        transformed_df = X_df.drop([\"address_street\", \"address_locality\", \"address_region\"], axis=1)\n",
    "        \n",
    "        # Thêm cột is_apt vào DataFrame (1 là thuộc chung cư, 0 là không không thuộc chung cư).\n",
    "        transformed_df[\"is_apt\"] = street_parsed[\"apt_unit\"].notnull().astype(int)\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7285\n",
       "1    1478\n",
       "Name: is_apt, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST AddressProcessor\n",
    "ap = AddressProcessor()\n",
    "\n",
    "ap.transform(train_X_df).is_apt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class DateSoldProcessor dùng để xử lý các cột date_sold và year_sold.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "\n",
    "class DateSoldProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, month_to_season = False):\n",
    "        self.month_to_season = month_to_season\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Rút trích month từ date_sold.\n",
    "        month = X_df.date_sold.str[:2].astype(int)\n",
    "        \n",
    "        # Xóa các cột không dùng nữa.\n",
    "        transformed_df = X_df.drop([\"date_sold\", \"year_sold\"], axis=1)\n",
    "        \n",
    "        if (self.month_to_season == False):\n",
    "            # Thêm cột month vào DataFrame (để tên là time_sold cho tiện truy cập).\n",
    "            transformed_df[\"time_sold\"] = month\n",
    "        else:\n",
    "            # 1 là Đông (tháng 12, 1, 2)\n",
    "            # 2 là Xuân (tháng 3, 4, 5)\n",
    "            # 3 là Hạ (tháng 6, 7, 8)\n",
    "            # 4 là Thu (tháng 9, 10, 11)\n",
    "            season = ((month.astype(int)%12 + 3)//3).astype(str)\n",
    "            # Thêm cột season_sold vào DataFrame (để tên là time_sold cho tiện truy cập).\n",
    "            transformed_df[\"time_sold\"] = season\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     1719\n",
       "8     1707\n",
       "9     1593\n",
       "10    1356\n",
       "6     1283\n",
       "11    1068\n",
       "5       12\n",
       "4        9\n",
       "3        7\n",
       "2        5\n",
       "1        4\n",
       "Name: time_sold, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST DateSoldProcessor\n",
    "dsp = DateSoldProcessor()\n",
    "\n",
    "dsp.transform(train_X_df).time_sold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4709\n",
       "4    4017\n",
       "2      28\n",
       "1       9\n",
       "Name: time_sold, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST DateSoldProcessor\n",
    "dsp = DateSoldProcessor(True)\n",
    "\n",
    "dsp.transform(train_X_df).time_sold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class InfoTypeProcessor dùng để xử lý cột info_type.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "\n",
    "class InfoTypeProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_types=1):\n",
    "        self.num_top_types = num_top_types\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        info_type_col = X_df.info_type\n",
    "        \n",
    "        # Đếm các dạng type trong cột info_type\n",
    "        self.type_counts_ = info_type_col.value_counts()\n",
    "        types = list(self.type_counts_.index)\n",
    "        \n",
    "        # Lấy ra top_type theo tham số num_top_types được truyền vào\n",
    "        self.top_types_ = types[:max(1, min(self.num_top_types, len(types)))]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Các cột không phải top_type được mặc định là \"Others\"\n",
    "        type_sr = X_df.info_type.str.extract(f'^({\"|\".join(self.top_types_)})$', expand=False).fillna(\"Others\")\n",
    "        \n",
    "        # Xóa đi cột info_type vì không dùng nữa.\n",
    "        transformed_df = X_df.drop([\"info_type\"], axis=1)\n",
    "        \n",
    "        # Thêm cột type vào DataFrame.\n",
    "        transformed_df[\"type\"] = type_sr\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Single Family Residence    5709\n",
       "Condominium                2399\n",
       "MISCELLANEOUS               326\n",
       "Multi-Family Dwellings      230\n",
       "Contact Agent                70\n",
       "Others                       29\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST InfoTypeProcessor\n",
    "itp = InfoTypeProcessor(num_top_types=5)\n",
    "\n",
    "itp.fit(train_X_df).transform(train_X_df).type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class TaxesProcessor dùng để xử lý các cột taxes_total và taxes_taxes.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "\n",
    "class TaxesProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        # Extract ra tiền thuế phải trả.\n",
    "        taxes = X_df.taxes_taxes.str.extract(r'(\\d+)', expand=False)\n",
    "        \n",
    "        # Xóa đi các cột không cần thiết.\n",
    "        transformed_df = X_df.drop([\"taxes_total\", \"taxes_taxes\"], axis=1)\n",
    "        \n",
    "        # Thêm cột taxes_taxes với giá trị mới extract được vào.\n",
    "        transformed_df[\"taxes_taxes\"] = taxes\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10555     16\n",
       "7259       8\n",
       "5026       7\n",
       "1014       6\n",
       "4127       6\n",
       "6076       6\n",
       "4973       6\n",
       "4875       6\n",
       "3759       5\n",
       "2669       5\n",
       "3688       5\n",
       "1310       5\n",
       "2545       5\n",
       "1152       5\n",
       "3011       5\n",
       "5753       5\n",
       "2749       5\n",
       "6029       5\n",
       "7190       5\n",
       "6540       5\n",
       "4986       5\n",
       "3634       5\n",
       "3606       5\n",
       "6333       4\n",
       "1244       4\n",
       "5901       4\n",
       "4301       4\n",
       "5076       4\n",
       "4356       4\n",
       "5695       4\n",
       "          ..\n",
       "2274       1\n",
       "16588      1\n",
       "7384       1\n",
       "12839      1\n",
       "11296      1\n",
       "995        1\n",
       "9073       1\n",
       "4960       1\n",
       "5301       1\n",
       "28593      1\n",
       "3051       1\n",
       "26568      1\n",
       "12497      1\n",
       "19356      1\n",
       "2884       1\n",
       "12434      1\n",
       "16118      1\n",
       "162919     1\n",
       "4755       1\n",
       "12914      1\n",
       "5489       1\n",
       "8358       1\n",
       "7377       1\n",
       "5034       1\n",
       "1977       1\n",
       "7792       1\n",
       "13771      1\n",
       "4242       1\n",
       "16113      1\n",
       "35333      1\n",
       "Name: taxes_taxes, Length: 6348, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST InfoTypeProcessor\n",
    "tp = TaxesProcessor()\n",
    "\n",
    "tp.fit(train_X_df).transform(train_X_df).taxes_taxes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class ColumnDropper dùng để xóa các cột info_property_id, info_county, info_parcel_number và mortgage.\n",
    "# Được kế thừa từ 2 class của Sklearn là BaseEstimator và TransformerMixin. \n",
    "# Việc kế thừa này giúp class của ta tự động có các phương thức như set_params, get_params, fit_transform.\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        transform_df = X_df.drop([\"info_property_id\", \"info_county\", \"info_parcel_number\", \"mortgage\"], axis=1)\n",
    "        #transform_df = X_df.drop([\"info_property_id\", \"info_county\", \"info_parcel_number\"], axis=1)\n",
    "        transform_df[\"address_code\"] = transform_df[\"address_code\"].astype(\"str\")\n",
    "        return transform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8763 entries, 10747 to 2732\n",
      "Data columns (total 22 columns):\n",
      "address_street        8736 non-null object\n",
      "address_locality      8763 non-null object\n",
      "address_region        8763 non-null object\n",
      "address_code          8763 non-null object\n",
      "date_sold             8763 non-null object\n",
      "mortgage              8763 non-null float64\n",
      "info_type             8763 non-null object\n",
      "info_bedrooms         7951 non-null float64\n",
      "info_bathrooms        7956 non-null float64\n",
      "info_size             8361 non-null float64\n",
      "info_lot_size         5931 non-null float64\n",
      "info_year_built       8099 non-null float64\n",
      "taxes_land            8632 non-null float64\n",
      "taxes_improvements    8632 non-null float64\n",
      "taxes_total           8632 non-null float64\n",
      "taxes_taxes           8632 non-null object\n",
      "school                8763 non-null int64\n",
      "total_crime           8498 non-null float64\n",
      "violent_crime         8498 non-null float64\n",
      "property_crime        8498 non-null float64\n",
      "foreclosures          8763 non-null int64\n",
      "year_sold             8763 non-null int64\n",
      "dtypes: float64(12), int64(3), object(7)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# TEST InfoTypeProcessor\n",
    "cd = ColumnDropper()\n",
    "\n",
    "cd.fit(train_X_df).transform(train_X_df).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class ColumnTransformerWithBaseColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, colTransformer, baseCol):\n",
    "        self.colTransformer = colTransformer\n",
    "        self.baseCol = baseCol\n",
    "\n",
    "    def fit(self, X_df, y=None):\n",
    "        self.train_X_df = X_df\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        colTransformer.fit()\n",
    "        transformed_df = X_df.copy()\n",
    "        transformed_df[\"type\"] = type_sr\n",
    "        return transformed_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8763x112 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 130533 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cols = [\"info_size\", \"info_lot_size\"]\n",
    "most_frequent_cols = [\"info_bedrooms\", \"info_bathrooms\"]\n",
    "mean_cols = [\"taxes_land\", \"taxes_improvements\", \"taxes_taxes\"]\n",
    "median_cols = [\"school\", \"foreclosures\", \"total_crime\", \"violent_crime\", \"property_crime\"]\n",
    "\n",
    "code_pipeline = Pipeline([(\"most_frequent\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"onehot\", OneHotEncoder())])\n",
    "\n",
    "type_pipeline = Pipeline([(\"most_frequent\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"onehot\", OneHotEncoder())])\n",
    "\n",
    "time_pipeline = Pipeline([(\"most_frequent\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                           (\"onehot\", OneHotEncoder())])\n",
    "\n",
    "\n",
    "column_transformer = ColumnTransformer([(\"knn\", KNNImputer(), knn_cols),\n",
    "                                        (\"most_frequent\", SimpleImputer(strategy=\"most_frequent\"), most_frequent_cols),\n",
    "                                        (\"mean\", SimpleImputer(strategy=\"mean\"), mean_cols),\n",
    "                                        (\"median\", SimpleImputer(strategy=\"median\"), median_cols),\n",
    "                                        (\"code_col\", code_pipeline, [\"address_code\"]),\n",
    "                                        (\"type_col\", type_pipeline, [\"type\"]),\n",
    "                                        (\"time_col\", time_pipeline, [\"time_sold\"])])\n",
    "\n",
    "\n",
    "preprocess_pipeline = Pipeline([(\"address\", AddressProcessor()),\n",
    "                                (\"date_sold\", DateSoldProcessor()),\n",
    "                                (\"info_type\", InfoTypeProcessor()),\n",
    "                                (\"col_dropper\", ColumnDropper()),\n",
    "                                (\"taxes\", TaxesProcessor()),\n",
    "                                (\"column_transformer\", column_transformer)])\n",
    "\n",
    "\n",
    "preprocess_pipeline.fit_transform(train_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3676110686066309"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                          (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                          (\"regression\", LinearRegression())])\n",
    "\n",
    "full_pipeline.fit(train_X_df, train_y_sr)\n",
    "full_pipeline.score(val_X_df, val_y_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With n = 1: 0.7219044459616868\n",
      "With n = 3: 0.7260192789749167\n",
      "With n = 5: 0.6924391144956822\n",
      "With n = 7: 0.5977965056021486\n",
      "With n = 9: 0.5426789336279418\n",
      "With n = 11: 0.4905314288717677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "N = [1, 3, 5, 7, 9, 11]\n",
    "for n in N:\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                              (\"regression\", KNeighborsRegressor(n_neighbors=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    accuracy = full_pipeline.score(val_X_df, val_y_sr)\n",
    "    print(\"With n = \" + str(n) + \": \" + str( accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20461060052249203"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                          (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                          (\"regression\", ElasticNet())])\n",
    "\n",
    "full_pipeline.fit(train_X_df, train_y_sr)\n",
    "full_pipeline.score(val_X_df, val_y_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With random_state = 0: 0.7925063653485082\n",
      "With random_state = 1: 0.6659847554537413\n",
      "With random_state = 2: 0.7839739401123859\n",
      "With random_state = 3: 0.6609784165823651\n",
      "With random_state = 4: 0.7839877423767306\n",
      "With random_state = 5: 0.6620189136073906\n",
      "With random_state = 6: 0.6515646438145635\n",
      "With random_state = 7: 0.6627584522469738\n",
      "With random_state = 8: 0.7872266236413078\n",
      "With random_state = 9: 0.7908534991879248\n",
      "With random_state = 10: 0.7838717840200333\n",
      "With random_state = 11: 0.7847374034637077\n",
      "With random_state = 12: 0.7878457517705085\n",
      "With random_state = 13: 0.6640095679046969\n",
      "With random_state = 14: 0.6539126524463794\n",
      "With random_state = 15: 0.6562580072686481\n",
      "With random_state = 16: 0.7808635129877541\n",
      "With random_state = 17: 0.6601832600773501\n",
      "With random_state = 18: 0.6600117004329101\n",
      "With random_state = 19: 0.6594240874107244\n",
      "With random_state = 20: 0.7936147602626978\n",
      "With random_state = 21: 0.7903337310328472\n",
      "With random_state = 22: 0.7803918817111278\n",
      "With random_state = 23: 0.7826935294876112\n",
      "With random_state = 24: 0.7885005740133194\n",
      "With random_state = 25: 0.7910955597285554\n",
      "With random_state = 26: 0.7887889218002794\n",
      "With random_state = 27: 0.7843503655705871\n",
      "With random_state = 28: 0.7813885480022872\n",
      "With random_state = 29: 0.7854703446915489\n",
      "With random_state = 30: 0.7866047258816264\n",
      "With random_state = 31: 0.6618993920615008\n",
      "With random_state = 32: 0.6650328376232172\n",
      "With random_state = 33: 0.7928220050402277\n",
      "With random_state = 34: 0.7876903536313242\n",
      "With random_state = 35: 0.7885863305442012\n",
      "With random_state = 36: 0.7921946715692911\n",
      "With random_state = 37: 0.7899942173305324\n",
      "With random_state = 38: 0.7881627118305263\n",
      "With random_state = 39: 0.7833310209965111\n",
      "With random_state = 40: 0.7797963970107533\n",
      "With random_state = 41: 0.780005180794111\n",
      "With random_state = 42: 0.7814538360196576\n",
      "With random_state = 43: 0.7901555556363073\n",
      "With random_state = 44: 0.6668118300882304\n",
      "With random_state = 45: 0.7843597543777746\n",
      "With random_state = 46: 0.7877967584716791\n",
      "With random_state = 47: 0.7916650003504202\n",
      "With random_state = 48: 0.784865677948581\n",
      "With random_state = 49: 0.7846271618653804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "for n in range(50):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                              (\"regression\", DecisionTreeRegressor(random_state=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    accuracy = full_pipeline.score(val_X_df, val_y_sr)\n",
    "    print(\"With random_state = \" + str(n) + \": \" + str( accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With random_state = 49: 0.7846271618653804\n",
      "With random_state = 50: 0.657705717768456\n",
      "With random_state = 51: 0.7903701063816483\n",
      "With random_state = 52: 0.789463193365913\n",
      "With random_state = 53: 0.7848317982743029\n",
      "With random_state = 54: 0.7821225563607986\n",
      "With random_state = 55: 0.780751800274875\n",
      "With random_state = 56: 0.7865036031389248\n",
      "With random_state = 57: 0.6680343865816866\n",
      "With random_state = 58: 0.7885686877880836\n",
      "With random_state = 59: 0.7828092171647087\n",
      "With random_state = 60: 0.6570193652062462\n",
      "With random_state = 61: 0.7812353669146882\n",
      "With random_state = 62: 0.7916158440034105\n",
      "With random_state = 63: 0.7864809773376831\n",
      "With random_state = 64: 0.7824400581118248\n",
      "With random_state = 65: 0.7883876450025604\n",
      "With random_state = 66: 0.7781623366322544\n",
      "With random_state = 67: 0.7864453557323444\n",
      "With random_state = 68: 0.7811652603708673\n",
      "With random_state = 69: 0.7793856210004718\n",
      "With random_state = 70: 0.6679552342903046\n",
      "With random_state = 71: 0.784203557141179\n",
      "With random_state = 72: 0.6560454857613605\n",
      "With random_state = 73: 0.7869968139667725\n",
      "With random_state = 74: 0.783558712991354\n",
      "With random_state = 75: 0.781275577944167\n",
      "With random_state = 76: 0.6550030780426935\n",
      "With random_state = 77: 0.6548454559949461\n",
      "With random_state = 78: 0.7901195905355066\n",
      "With random_state = 79: 0.7936019495435156\n",
      "With random_state = 80: 0.6626109004903711\n",
      "With random_state = 81: 0.778211417536435\n",
      "With random_state = 82: 0.6658382603689743\n",
      "With random_state = 83: 0.7861322678598517\n",
      "With random_state = 84: 0.7956127579317661\n",
      "With random_state = 85: 0.7853728665431611\n",
      "With random_state = 86: 0.7811276016517049\n",
      "With random_state = 87: 0.791231234031918\n",
      "With random_state = 88: 0.6589321499846983\n",
      "With random_state = 89: 0.7829106373119263\n",
      "With random_state = 90: 0.7902627098379075\n",
      "With random_state = 91: 0.7846935434224254\n",
      "With random_state = 92: 0.7834979265040861\n",
      "With random_state = 93: 0.7870312954510106\n",
      "With random_state = 94: 0.6589636567308652\n",
      "With random_state = 95: 0.6630759960058892\n",
      "With random_state = 96: 0.7917735780786057\n",
      "With random_state = 97: 0.6605405214725029\n",
      "With random_state = 98: 0.7802477491377865\n",
      "With random_state = 99: 0.783847142963712\n",
      "With random_state = 100: 0.6532232433166829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "for n in range(49,101):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                              (\"regression\", DecisionTreeRegressor(random_state=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    accuracy = full_pipeline.score(val_X_df, val_y_sr)\n",
    "    print(\"With random_state = \" + str(n) + \": \" + str( accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With random_state = 0: 0.7999780262108753\n",
      "With random_state = 1: 0.7867585720678776\n",
      "With random_state = 2: 0.8350462151858227\n",
      "With random_state = 3: 0.800456280158938\n",
      "With random_state = 4: 0.7857022131635122\n",
      "With random_state = 5: 0.8161527277201609\n",
      "With random_state = 6: 0.7975735193356739\n",
      "With random_state = 7: 0.7995885075806872\n",
      "With random_state = 8: 0.8091569923327382\n",
      "With random_state = 9: 0.8270965165055384\n",
      "With random_state = 10: 0.8088404087140052\n",
      "With random_state = 11: 0.8224852445178769\n",
      "With random_state = 12: 0.8116496251875935\n",
      "With random_state = 13: 0.8006188520567398\n",
      "With random_state = 14: 0.8154819436159858\n",
      "With random_state = 15: 0.8120454536422175\n",
      "With random_state = 16: 0.8076591079462648\n",
      "With random_state = 17: 0.8286823148798782\n",
      "With random_state = 18: 0.7925045577657999\n",
      "With random_state = 19: 0.8116078600836041\n",
      "With random_state = 20: 0.7977932009328877\n",
      "With random_state = 21: 0.8074731858629904\n",
      "With random_state = 22: 0.7858813281110458\n",
      "With random_state = 23: 0.8023932272322671\n",
      "With random_state = 24: 0.811613690739341\n",
      "With random_state = 25: 0.803858988100306\n",
      "With random_state = 26: 0.7740981295806633\n",
      "With random_state = 27: 0.784940523642568\n",
      "With random_state = 28: 0.7855718839397472\n",
      "With random_state = 29: 0.8037306709863536\n",
      "With random_state = 30: 0.8177617935297479\n",
      "With random_state = 31: 0.8179134784129586\n",
      "With random_state = 32: 0.8013430489971352\n",
      "With random_state = 33: 0.8137451246729028\n",
      "With random_state = 34: 0.8040184068932981\n",
      "With random_state = 35: 0.8184747356619944\n",
      "With random_state = 36: 0.7979879597411216\n",
      "With random_state = 37: 0.799935613976663\n",
      "With random_state = 38: 0.8145014130121953\n",
      "With random_state = 39: 0.7977319811595457\n",
      "With random_state = 40: 0.80835773940072\n",
      "With random_state = 41: 0.8209517224130409\n",
      "With random_state = 42: 0.7953806520137169\n",
      "With random_state = 43: 0.7924784231925035\n",
      "With random_state = 44: 0.8131218210682738\n",
      "With random_state = 45: 0.8000758612223025\n",
      "With random_state = 46: 0.8014478305367357\n",
      "With random_state = 47: 0.8143907261896557\n",
      "With random_state = 48: 0.8110463217241101\n",
      "With random_state = 49: 0.7830744124347797\n",
      "With random_state = 50: 0.7974484055179947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "for n in range(0,51):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                              (\"regression\", GradientBoostingRegressor(random_state=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    accuracy = full_pipeline.score(val_X_df, val_y_sr)\n",
    "    print(\"With random_state = \" + str(n) + \": \" + str( accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/junkal/selecting-the-best-regression-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With n_trees = 10: 0.7680782711703396\n",
      "With n_trees = 11: 0.7941500164790997\n",
      "With n_trees = 12: 0.7428607908578331\n",
      "With n_trees = 13: 0.8151927248615991\n",
      "With n_trees = 14: 0.7687711487859537\n",
      "With n_trees = 15: 0.8251480930437328\n",
      "With n_trees = 16: 0.7934635073460735\n",
      "With n_trees = 17: 0.7571777419993032\n",
      "With n_trees = 18: 0.7928195966532341\n",
      "With n_trees = 19: 0.7839380825664696\n",
      "With n_trees = 20: 0.7516249047511813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for n in range(10, 21):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                              (\"regression\", RandomForestRegressor(n_estimators=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    accuracy = full_pipeline.score(val_X_df, val_y_sr)\n",
    "    print(\"With n_trees = \" + str(n) + \": \" + str( accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With n_trees = 21: 0.7994778835506996\n",
      "With n_trees = 22: 0.7826073302057023\n",
      "With n_trees = 23: 0.7818011289822785\n",
      "With n_trees = 24: 0.7853851100679016\n",
      "With n_trees = 25: 0.776069950490403\n",
      "With n_trees = 26: 0.8279547184418456\n",
      "With n_trees = 27: 0.8068720668003042\n",
      "With n_trees = 28: 0.8377148658342689\n",
      "With n_trees = 29: 0.8251455026740729\n",
      "With n_trees = 30: 0.7927289643855973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for n in range(21, 31):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                              (\"regression\", RandomForestRegressor(n_estimators=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    accuracy = full_pipeline.score(val_X_df, val_y_sr)\n",
    "    print(\"With n_trees = \" + str(n) + \": \" + str( accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With random_state = 0: 0.7977509742093444\n",
      "With random_state = 1: 0.8093499910266685\n",
      "With random_state = 2: 0.8051308581115851\n",
      "With random_state = 3: 0.8063576555764645\n",
      "With random_state = 4: 0.7819483132699812\n",
      "With random_state = 5: 0.8093965655598084\n",
      "With random_state = 6: 0.8116561133660033\n",
      "With random_state = 7: 0.8211473233633331\n",
      "With random_state = 8: 0.7999900312565849\n",
      "With random_state = 9: 0.8091801674703056\n",
      "With random_state = 10: 0.7996988971647787\n",
      "With random_state = 11: 0.816591975409707\n",
      "With random_state = 12: 0.7972444990900895\n",
      "With random_state = 13: 0.7885888275601943\n",
      "With random_state = 14: 0.8078394361892346\n",
      "With random_state = 15: 0.8036448802564152\n",
      "With random_state = 16: 0.8248270254819615\n",
      "With random_state = 17: 0.8057498429239374\n",
      "With random_state = 18: 0.7976152645704063\n",
      "With random_state = 19: 0.7913858077929808\n",
      "With random_state = 20: 0.8132527716351619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for n in range(21):\n",
    "    full_pipeline = Pipeline([(\"preprocess\", preprocess_pipeline),\n",
    "                              (\"std_scaler\", StandardScaler(with_mean=False)),\n",
    "                              (\"regression\", RandomForestRegressor(random_state=n))])\n",
    "\n",
    "    full_pipeline.fit(train_X_df, train_y_sr)\n",
    "    accuracy = full_pipeline.score(val_X_df, val_y_sr)\n",
    "    print(\"With random_state = \" + str(n) + \": \" + str( accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
